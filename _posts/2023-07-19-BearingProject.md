---
layout: single
title: "[ë² ì–´ë§ ê³ ì¥ ì§„ë‹¨ í”„ë¡œì íŠ¸]/Nasa Dataset"
categories: ì´ìƒê°ì§€
tag: [ì´ìƒê°ì§€, ì‹ í˜¸ì²˜ë¦¬]
toc: true
author_profile: false
sidebar:
  nav: "docs"
---

# ë² ì–´ë§ ê³ ì¥ ì§„ë‹¨ í”„ë¡œì íŠ¸- Nasa Bearing Dataset

## ğŸ¯Domain Analysis:

**ë„ë©”ì¸ ë¶„ì„(ë°°ê²½ ë¶„ì„)ì€ ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì„ì„ í•  ë•Œ ê°€ì¥ ì¤‘ìš”í•œ ê³¼ì •ì´ë‹¤**. ë¶„ì„í•˜ê³ ì í•˜ëŠ” ëŒ€ìƒì„ ì˜ ì´í•´í•´ì•¼ ê·¸ì— ì í•©í•œ ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„ì„ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤. ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œ í’€ê³ ì í•˜ëŠ” ë„ë©”ì¸ì€ ë² ì–´ë§ ì˜ˆì§€ ì •ë¹„ì´ë‹¤. ì˜ˆì§€ ì •ë¹„ë€ ì´ìƒì¹˜ë¥¼ íƒì§€í•˜ì—¬ ì„¤ë¹„ì˜ ê³ ì¥ ì´ì „ì— ì •ë¹„ë¥¼ í•˜ëŠ” ê²ƒì„ ë§í•œë‹¤.

### âš™ ë² ì–´ë§:

**ë² ì–´ë§ì´ë€ 'íšŒì „ìš´ë™ì„ í•˜ëŠ” ì¶•ì„ ì¼ì •í•œ ìœ„ì¹˜ì—ì„œ ì§€ì§€í•˜ì—¬ ìš´ë™ì„ ì œí•œí•˜ê³  ë§ˆì°°ì„ ì¤„ì—¬ì£¼ëŠ” ê¸°ê³„ìš”ì†Œ'ë¥¼ ì§€ì¹­í•œë‹¤**. ë² ì–´ë§ì€ ê±°ì˜ ëª¨ë“  íšŒì „ì²´ì— í¬í•¨ëœë‹¤ê³  í•  ìˆ˜ ìˆë‹¤. ìš°ë¦¬ê°€ í”íˆ ì•Œê³  ìˆëŠ” ìë™ì°¨ ë°”í€´ì—ë„ ë² ì–´ë§ì´ ì‚¬ìš©ëœë‹¤. ë² ì–´ë§ì´ ì—†ì´ ë°”í€´ì¶•ì´ ì˜¨ì „íˆ ì§€íƒ±í•˜ê²Œ í–ˆì„ ì‹œ, ë°”í€´ ì¶•ì´ í˜ì„ ì˜¨ì „íˆ ë°›ì•„ ë¹ ë¥´ê²Œ ë§ˆëª¨ë  ê°€ëŠ¥ì„±ì´ ìˆë‹¤. ì´ë ‡ë“¯ íšŒì „ì²´ê°€ íšŒì „ì‹œì— ë§ˆì°°ì„ íšê¸°ì ìœ¼ë¡œ ê°ì†Œì‹œí‚¤ëŠ” ì£¼ìš” ì„¤ë¹„ì´ë‹¤.

ë² ì–´ë§ ì¢…ë¥˜ëŠ” ìŠ¬ë¦¬ë¸Œ ë² ì–´ë§, êµ¬ë¦„ ë² ì–´ë§ í¬ê²Œ ë‘ê°€ì§€ë¡œ ë‚˜ë‰œë‹¤. ê·¸ ì¤‘ Nasa Bearing Datasetì— ì‚¬ìš©ë˜ëŠ” ë² ì–´ë§ì€ **êµ¬ë¦„ ë² ì–´ë§ì´ë‹¤**. êµ¬ë¦„ ë² ì–´ë§ì˜ êµ¬ì¡°ëŠ” Cage ë‚´ì— ê³ ì •ë˜ëŠ” êµ¬ë¦„ìš”ì†Œ, ì•ˆìª½ ë‚´ë¥œ, ê·¸ë¦¬ê³  ë°”ê¹¥ ìª½ ì™¸ë¥œìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ë² ì–´ë§ ê²°í•¨ì€ ì´ëŸ¬í•œ êµ¬ì„±ìš”ì†Œ ì–´ë””ì—ì„œë“ ì§€ ì§„í–‰ ë  ìˆ˜ ìˆë‹¤.

**ë² ì–´ë§ì— í•˜ë‚˜ì˜ ê²°í•¨ì´ ë°œìƒí•˜ë©´ ê²°í•¨ ì£¼íŒŒìˆ˜ê°€ ìƒê¸°ê²Œ ë˜ë©° ì„±ì¥ì‹œ ë² ì–´ë§ ë‚´ì— ë‹¤ë¥¸ ê²°í•¨ì„ ì¼ìœ¼í‚¤ê²Œ í•  ìˆ˜ ìˆë‹¤.** ì´ë ‡ê²Œ ë˜ë©´ ì–´ë–¤ ì£¼íŒŒìˆ˜ë“¤ì´ ë‹¤ë¥¸ ì£¼íŒŒìˆ˜ë¥¼ ë”í•˜ê±°ë‚˜ ë¹¼ ì£¼ê¸°ë„ í•œë‹¤. ì‹¤ì œë¡œ ë² ì–´ë§ ê²°í•¨ì´ ë°œìƒí•  ì‹œ ê¸°ë³¸ ì£¼íŒŒìˆ˜ë§Œ ì¶œë ¥ë˜ëŠ” ê²½ìš°ëŠ” ì—†ë‹¤. **ê²°í•¨ ì£¼íŒŒìˆ˜ëŠ” ì´ë¯¸ ì¡´ì¬í•˜ê³  ìˆëŠ” ë‹¤ë¥¸ ì£¼íŒŒìˆ˜ë“¤ì˜ ì¸¡ëŒ€íŒŒë¡œì¨ ì‘ìš©í•œë‹¤.** ì˜ˆë¥¼ ë“¤ì–´, Cageì—ì„œ ê²°í•¨ì´ ë°œìƒí•  ì‹œ, Cage ìì²´ ê²°í•¨ ì£¼íŒŒìˆ˜ëŠ” ë°œìƒí•˜ì§€ ì•ŠëŠ”ë‹¤. ëŒ€ì‹ , ì™¸ë¥œ ë° ë‚´ë¥œì˜ ì£¼íŒŒìˆ˜ í˜¹ì€ êµ¬ë¦„ìš”ì†Œì˜ ê²°í•¨ ì£¼íŒŒìˆ˜ì˜ ì¸¡ëŒ€íŒŒë¡œ ë‚˜íƒ€ë‚˜ê²Œ ëœë‹¤. **ë”°ë¼ì„œ ë¬¸ì œì˜ ëª©ì ì— ë”°ë¼ êµ¬í•˜ê³ ì í•˜ëŠ” ê³ ì • ì£¼íŒŒìˆ˜ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ì„œëŠ” filtering ë°©ë²•ì´ ì‚¬ìš©ë˜ì–´ì•¼ í•œë‹¤.**

### ğŸ“ˆFiltering ë°©ë²•:

**ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ë² ì–´ë§ ì£¼íŒŒìˆ˜ë¥¼ êµ¬í•  ë•Œ ë² ì–´ë§ ê²°í•¨ ê³ ìœ  ì£¼íŒŒìˆ˜ê°€ ì¸¡ì •ë˜ëŠ” ê²ƒì´ ì•„ë‹Œ ë‹¤ë¥¸ ìš”ì†Œì— ì˜í•œ ì¸¡ëŒ€íŒŒë¡œ ë‚˜íƒ€ë‚œë‹¤.** ë”°ë¼ì„œ ë°›ì€ ì¸¡ëŒ€íŒŒë¥¼ filtering ë°©ë²•ì„ ê±°ì³ ê³ ìœ  ì£¼íŒŒìˆ˜ë¥¼ êµ¬í•´ì£¼ëŠ” ê³¼ì •ì„ ê±°ì³ì•¼ í•œë‹¤. ì´ë•Œ ì‚¬ìš©ë˜ëŠ” **Filtering ë°©ë²•ìœ¼ë¡œëŠ” FFT, PSD, Auto correlation, Spectral Kurtosis + Hilbert transformì´ ìˆë‹¤.** Spectral Kurtosis ë° Hilbert transform ê´€ë ¨ ë‚´ìš©ì€ ì¶”í›„ì— ë‹¤ë£¨ê¸°ë¡œ í•˜ê³  ë‚˜ë¨¸ì§€ filtering ë°©ë²•ì— ëŒ€í•´ì„œ ë‹¤ë£¨ê² ë‹¤.

ì´ëŸ¬í•œ Filteringì„ ì´í•´í•˜ê¸° ì•ì„œ ê¸°ë³¸ì ì¸ ì‹ í˜¸ì²˜ë¦¬ ë°©ë²•ì— ëŒ€í•´ ì•Œ í•„ìš”ê°€ ìˆë‹¤.

ì‹ í˜¸ëŠ” ìš°ë¦¬ì˜ ì¼ìƒìƒí™œì˜ ì¼ë¶€ë¶„ì´ë‹¤. ì˜¤ë””ì˜¤ ì‹ í˜¸, ì‚¬ì§„, ë¹„ë””ì˜¤ ëª¨ë‘ ì‹ í˜¸ í˜•íƒœë¡œ ìˆë‹¤. ì´ëŸ¬í•œ ì‹ í˜¸ëŠ” ì—°ì†ì ì¸ ì‹ í˜¸, ì´ì‚°ì ì¸ ì‹ í˜¸ ë‘ê°€ì§€ë¡œ ë‚˜ë‰œë‹¤. ì—°ì†ì ì¸ ì‹ í˜¸ëŠ” ìš°ë¦¬ê°€ ìì—° ìƒíƒœì—ì„œ ë“¤ì„ ìˆ˜ ìˆëŠ” ì‹ í˜¸ë“¤ì´ë‹¤. ë°˜ë©´ ì´ì‚°ì ì¸ ì‹ í˜¸ ê°™ì€ ê²½ìš°, ìì—° ìƒíƒœì˜ ì‹ í˜¸ë¥¼ ë””ì§€í„¸í™” í•  ë•Œ ë§ì´ ì‚¬ìš©ëœë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì„ í• ë•Œ ì¸¡ì •ëœ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ë¶„ì„ì„ í•´ì•¼ í•˜ë¯€ë¡œ ì´ì‚°ì‹ í˜¸ë¥¼ ë‹¤ë£¨ê²Œ ë  ê²ƒì´ë‹¤. ì´ë ‡ê²Œ ì‹ í˜¸ë¥¼ ê°€ì§€ê³  ë¶„ì„ì„ í•˜ëŠ” ê²ƒì„ ì‹ í˜¸ì²˜ë¦¬ë¼ê³  í•œë‹¤.

ì—°ì†ì ì¸ ì‹ í˜¸ë¥¼ ì´ì‚°ì ìœ¼ë¡œ ë°”ê¾¸ëŠ” ê³¼ì •ì—ì„œ íŠ¹ì • sampling rateì—ì„œ samplingì„ í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹˜ê²Œ ëœë‹¤.

![sampling_ì‚¬ì§„.png]({{site.url}}/images/2023-07-19-BearingProject/sampling_ì‚¬ì§„.png){: .align-center}

ê·¸ë¦¼ì—ì„œ ë³´ë‹¤ì‹œí”¼, sample rateì„ 10Hzë¡œ í–ˆì„ ë•Œ ë” ë§ì€ ë°ì´í„°ë¥¼ ë½‘ê²Œ ë˜ê³  ë” ì •êµí•˜ê²Œ ë³µì›í•  ìˆ˜ ìˆë‹¤. ë°˜ë©´ sample rateì„ 5Hzë¡œ í–ˆì„ ë•Œ ë°ì´í„°ë¥¼ ì ê²Œ ë½‘ê²Œ ë˜ê³  ëœ ì •êµí•œ ê·¸ë˜í”„ë¥¼ ë³µì›í•˜ê²Œ ëœë‹¤. Sample rateì„ ë‚˜ì´í€´ìŠ¤íŠ¸ rateë³´ë‹¤ ì ê²Œ ë½‘ì•˜ì„ ì‹œ, ì›ë³¸(ìì—° ë°ì´í„°)ë¥¼ ë³µì›í•  ìˆ˜ ì—†ê²Œ ëœë‹¤. ë”°ë¼ì„œ ìƒ˜í”Œë§ì„ í•  ë•ŒëŠ” ë‚˜ì´í€˜ìŠ¤íŠ¸ rateë³´ë‹¤ í¬ê²Œ ë½‘ì•„ì•¼ í•œë‹¤.

#### í‘¸ë¦¬ì— ë³€í™˜(Fast Fourier Transform)

ê°€ì¥ ëŒ€í‘œì ì¸ ì‹ í˜¸ì²˜ë¦¬ ë°©ë²•ì´ **Fast Fourier Transformì´ë‹¤**. í‘¸ë¦¬ì— ë³€í™˜ì€ ì‹ í˜¸ì˜ ì£¼ê¸°ì„±ì„ ê³µë¶€í•  ë•Œ ì‚¬ìš©ë˜ëŠ” ë°©ë²•ì´ë‹¤. **í‘¸ë¦¬ì— ë³€í™˜ì€ ì‹ í˜¸ë“¤ì„ ì£¼íŒŒìˆ˜ ì„±ë¶„ìœ¼ë¡œ ë¶„í•´í•˜ëŠ” ë°©ë²•ì´ë‹¤**.

**ëª¨ë“  ì‹ í˜¸ëŠ” ë” ê°„ë‹¨í•œ í˜•íƒœì˜ ì‹ í˜¸ ì‹¸ì¸ í˜¹ì€ ì½”ì‹¸ì¸ í˜•íƒœì˜ ì‹ í˜¸ì˜ í•© í˜•íƒœë¡œ ë¶„í•´ê°€ ê°€ëŠ¥í•˜ë‹¤**. ì‹œê°„ ì˜ì—­ì—ì„œ ì£¼íŒŒìˆ˜ ì˜ì—­ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì„ í‘¸ë¦¬ì— ë³€í™˜ì´ë¼ê³  ë¶€ë¥¸ë‹¤. ë°˜ëŒ€ ê³¼ì •(ì£¼íŒŒìˆ˜ ì˜ì—­ì—ì„œ ì‹œê°„ ì˜ì—­ìœ¼ë¡œ ë³€í™˜)í•˜ëŠ” ê²ƒì„ ì—­í‘¸ë¦¬ì— ë³€í™˜ì´ë¼ê³  í•œë‹¤.

```python

from scipy.fftpack import fft

def get_fft_values(y_values, T, N, f_s):
    f_values = np.linspace(0.0, 1.0/(2.0*T), N//2)
    fft_values_ = fft(y_values)
    fft_values = 2.0/N * np.abs(fft_values_[0:N//2])
    return f_values, fft_values

t_n = 10
N = 1000
T = t_n / N
f_s = 1/T

f_values, fft_values = get_fft_values(composite_y_value, T, N, f_s)

plt.plot(f_values, fft_values, linestyle='-', color='blue')
plt.xlabel('Frequency [Hz]', fontsize=16)
plt.ylabel('Amplitude', fontsize=16)
plt.title("Frequency domain of the signal", fontsize=16)
plt.show()
```

![image-20230719215524620]({{site.url}}/images/2023-07-19-BearingProject/image-20230719215524620.png){: .align-center}

ìœ„ ê·¸ë¦¼ ê°™ì€ ê²½ìš° fsê°€ 100Hzì´ê¸° ë•Œë¬¸ì— FFT ìŠ¤í™íŠ¸ëŸ¼ì€ fs/2ì¸ 50Hzì´ë‹¤. fs ê°’ì´ í´ìˆ˜ë¡ FFTì—ì„œ ë” í° ì£¼íŒŒìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆê²Œ ëœë‹¤.

ìœ„ get_fft_values í•¨ìˆ˜ ê°™ì€ ê²½ìš°, ë³µì¡í•œ ì‹ í˜¸ì˜ ì£¼íŒŒìˆ˜ ë²¡í„° ê°’ì„ returní•˜ê²Œ ëœë‹¤. ë˜í•œ ìš°ë¦¬ê°€ ê´€ì‹¬ì„ ê°–ëŠ” ê²ƒì€ ì¦í­ì˜ ì •ë„ì´ê¸° ë•Œë¬¸ì— ì ˆëŒ“ê°’ì„ ì·¨í•œë‹¤.

FFTëŠ” N pointsì˜ ì‹ í˜¸ ê°’ì„ return í•  ê²ƒì´ê³  ì´ì˜ N/2 ê°’ì´ ì˜ë¯¸ ìˆëŠ” ê°’ì´ë©° ê·¸ ì „ ê°’ë“¤ì€ ìœ ì˜í•˜ì§€ ì•Šë‹¤.

#### PSD

PSDëŠ” í‘¸ë¦¬ì— ë³€í™˜ê³¼ ë©”ìš° ë°€ì ‘í•œ ì—°ê´€ì´ ìˆë‹¤. PSD ê°™ì€ ê²½ìš°, FFTê°’ì´ ë‹¨ìˆœíˆ ì‹ í˜¸ì˜ ì£¼íŒŒìˆ˜ í˜•íƒœì˜ ìŠ¤í™íŠ¸ëŸ¼ì„ êµ¬í•œ ê²ƒì´ë¼ë©´, **PSDëŠ” ê·¸ê²ƒì— íŒŒì›Œ ì •ë„ë„ êµ¬í•œ ê²ƒì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤**. í‘¸ë¦¬ì— ë³€í™˜ê³¼ ê±°ì˜ ìœ ì‚¬í•˜ë‚˜ ê° ì‹ í˜¸ì˜ peak ê°’ì˜ ë†’ì´ ë° ë„“ì´ê°€ ë‹¤ë¥¼ ê²ƒì´ë‹¤.

![image-20230719222021425]({{site.url}}/images/2023-07-19-BearingProject/image-20230719222021425.png){: .align-center}

ìœ„ ê·¸ë¦¼ì€ PSDë¥¼ ì‹œê°í™”í•œ ê²ƒì´ë‹¤.

Scipyì—ì„œ ì œê³µí•˜ê¸° ë•Œë¬¸ì— PSD(Power Spectral Density)ë¥¼ ì½”ë”©ìœ¼ë¡œ ê³„ì‚°í•˜ëŠ” ê²ƒì€ ì‰½ë‹¤.

```python
from scipy.signal import welch

def get_psd_values(y_values, T, N, f_s):
    f_values, psd_values = welch(y_values, fs=f_s)
    return f_values, psd_values


t_n = 10
N = 1000
T = t_n / N
f_s = 1/T

f_values, psd_values = get_psd_values(composite_y_value, T, N, f_s)

plt.plot(f_values, psd_values, linestyle='-', color='blue')
plt.xlabel('Frequency [Hz]')
plt.ylabel('PSD [V**2 / Hz]')
plt.show()

```

#### Auto-correlation(ìê¸° ìƒê´€)

**ìê¸° ìƒê´€í•¨ìˆ˜ëŠ” ì‹ í˜¸ì™€ ì‹œê°„ ì§€ì—°ëœ ì‹ í˜¸ ìì²´ì˜ ìƒê´€ê³„ìˆ˜ë¥¼ ê³„ì‚°í•œë‹¤**. ì–´ë–¤ ì‹ í˜¸ì— T secë™ì•ˆ í•˜ë‚˜ì˜ ì£¼ê¸°ë¥¼ ë°˜ë³µì„ í•˜ë©´, í•´ë‹¹ ì‹ í˜¸ì™€ í•´ë‹¹ ì‹ í˜¸ T ì‹œê°„ ì§€ì—°ëœ ì‹ í˜¸ì™€ ê°•í•œ ìƒê´€ê´€ê³„ê°€ ìˆì„ ê²ƒì´ë‹¤. ì´ëŸ¬í•œ ì›ë¦¬ë¥¼ í™œìš©í•˜ëŠ” ê²ƒì´ ìê¸° ìƒê´€í•¨ìˆ˜ì´ë‹¤.

```python

def autocorr(x):
    result = np.correlate(x, x, mode='full')
    return result[len(result)//2:]

def get_autocorr_values(y_values, T, N, f_s):
    autocorr_values = autocorr(y_values)
    x_values = np.array([T * jj for jj in range(0, N)])
    return x_values, autocorr_values

t_n = 10
N = 1000
T = t_n / N
f_s = 1/T

t_values, autocorr_values = get_autocorr_values(composite_y_value, T, N, f_s)

plt.plot(t_values, autocorr_values, linestyle='-', color='blue')
plt.xlabel('time delay [s]')
plt.ylabel('Autocorrelation amplitude')
plt.show()
```

![image-20230720145315485]({{site.url}}/images/2023-07-19-BearingProject/image-20230720145315485.png){: .align-center}

ìê¸° ìƒê´€í•¨ìˆ˜ë¥¼ í†µí•´ ìƒì„±ëœ ê°’ì˜ Peakê°’ì˜ ì‹œê°„ ì¶•ì„ ì£¼íŒŒìˆ˜ ì¶•ìœ¼ë¡œ ë³€í™˜í•˜ë©´ FFTì™€ ê°™ì€ ê°’ê³¼ ê°™ê²Œ ëœë‹¤.

#### âš¡Wavelet ë°©ë²•:

ì•ì„œ í‘¸ë¦¬ì— ë³€í™˜ì— ëŒ€í•´ì„œ ë°°ìš´ ë°” ìˆë‹¤. í‘¸ë¦¬ì— ë³€í™˜ì€ ì‹ í˜¸ë¥¼ ì‹œê°„ ì°¨ì›ì—ì„œ ì£¼íŒŒìˆ˜ ì°¨ì›ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë° íšê¸°ì ì¸ ê¸°ë²•ì´ì§€ë§Œ **ì‹œê°„ì„ ë°˜ì˜í•˜ì§€ ëª»í•œë‹¤ëŠ” ì¹˜ëª…ì ì¸ ë‹¨ì ì´ ì¡´ì¬í•œë‹¤.**

```python
t_n = 1
N = 100000
T = t_n / N
f_s = 1/T

xa = np.linspace(0, t_n, num=N)
xb = np.linspace(0, t_n/4, num=N/4)

frequencies = [4, 30, 60, 90]
y1a, y1b = np.sin(2*np.pi*frequencies[0]*xa), np.sin(2*np.pi*frequencies[0]*xb)
y2a, y2b = np.sin(2*np.pi*frequencies[1]*xa), np.sin(2*np.pi*frequencies[1]*xb)
y3a, y3b = np.sin(2*np.pi*frequencies[2]*xa), np.sin(2*np.pi*frequencies[2]*xb)
y4a, y4b = np.sin(2*np.pi*frequencies[3]*xa), np.sin(2*np.pi*frequencies[3]*xb)

composite_signal1 = y1a + y2a + y3a + y4a
composite_signal2 = np.concatenate([y1b, y2b, y3b, y4b])

f_values1, fft_values1 = get_fft_values(composite_signal1, T, N, f_s)
f_values2, fft_values2 = get_fft_values(composite_signal2, T, N, f_s)

fig, axarr = plt.subplots(nrows=2, ncols=2, figsize=(12,8))
axarr[0,0].plot(xa, composite_signal1)
axarr[1,0].plot(xa, composite_signal2)
axarr[0,1].plot(f_values1, fft_values1)
axarr[1,1].plot(f_values2, fft_values2)
(...)
plt.tight_layout()
plt.show()
```

![image-20230720150430725]({{site.url}}/images/2023-07-19-BearingProject/image-20230720150430725.png){: .align-center}

ìœ„ ê·¸ë¦¼ì—ì„œë„ ë³¼ ìˆ˜ ìˆë“¯ì´ Signal1ê³¼ Signal2ëŠ” ë‹¤ë¥¸ íŒŒí˜•ì„ ë„ê³  ìˆë‹¤. **í•˜ì§€ë§Œ í‘¸ë¦¬ì— ë³€í™˜ ì‹œ ë™ì¼í•œ ê°’ì„ êµ¬í•œë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤**. ì´ëŠ” í‘¸ë¦¬ì— ë³€í™˜ì„ í•  ì‹œ ì‹œê°„ ì°¨ì›ì„ ê³ ë ¤í•˜ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì´ë‹¤.

ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ STFT(short term Fourier Transform)ì´ë¼ëŠ” ê¸°ë²•ì´ ì‚¬ìš©ë˜ê¸°ë„ í•œë‹¤. **í•´ë‹¹ ë°©ë²•ì€ ì›ë³¸ ì‹ í˜¸ë¥¼ ë™ì¼í•œ ê¸¸ì´ì˜ windowë¥¼ ê°€ì§€ê³  ë‚˜ëˆ ì„œ í‘¸ë¦¬ì— ë³€í™˜ì„ í•˜ëŠ” ê²ƒì´ë‹¤**. ì˜ˆë¥¼ ë“¤ì–´, í•˜ë‚˜ì˜ ì‹ í˜¸ë¥¼ 10ê°œì˜ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆˆë‹¤ê³  í•  ë•Œ, 2ë²ˆì§¸ êµ¬ê°„ì„ ë³´ë ¤ê³  í•˜ë©´, í•´ë‹¹ ì£¼ê¸°ì˜ 2/10ì—ì„œ 3/10ì´ ë˜ëŠ” êµ¬ê°„ì„ ì°¾ìœ¼ë©´ ëœë‹¤.

í•˜ì§€ë§Œ STFT ë˜í•œ í‘¸ë¦¬ì— ë³€í™˜ì˜ ì¼í™˜ì´ê¸° ë•Œë¬¸ì— **í‘¸ë¦¬ì— ë³€í™˜ì˜ ë¶ˆí™•ì‹¤ì„± ì›ì¹™ì´ë¼ëŠ” ë¬¸ì œì—ì„œ ììœ ë¡­ì§€ ëª»í•˜ë‹¤**. STFTì—ì„œ ìœˆë„ìš° í¬ê¸°ë¥¼ ì¤„ì¼ìˆ˜ë¡ ì‹ í˜¸ ìœ„ì¹˜ë¥¼ íŒŒì•…í•˜ê¸° ì‰½ì§€ë§Œ ì£¼íŒŒìˆ˜ì˜ ê°’ì„ êµ¬í•˜ê¸´ ì–´ë ¤ì›Œì§„ë‹¤. ë°˜ë©´, ìœˆë„ìš° í¬ê¸°ë¥¼ í‚¤ìš¸ ìˆ˜ë¡ ì£¼íŒŒìˆ˜ì˜ ê°’ì„ êµ¬í•˜ê¸´ ì‰¬ì›Œì§€ì§€ë§Œ ì‹ í˜¸ì˜ ìœ„ì¹˜ë¥¼ êµ¬í•˜ê¸´ ì–´ë ¤ì›Œì§„ë‹¤.

ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë°©ë²•ìœ¼ë¡œ Wavelet Transformì´ ìˆë‹¤.

í‘¸ë¦¬ì— ë³€í™˜ì€ ì‹¸ì¸í˜•íƒœë¡œ ì‹ í˜¸ë¥¼ ë°˜í™˜í•œë‹¤. ì™œëƒí•˜ë©´ í•˜ë‚˜ì˜ ì‹ í˜¸ê°€ ì‹¸ì¸ ì‹ í˜¸ì˜ ì„ í˜•ì‹ìœ¼ë¡œ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì´ë‹¤.

Waveletì€ ì‹¸ì¸í˜•íƒœì˜ ì‹ í˜¸ê°€ ì•„ë‹Œ ë‹¤ì–‘í•œ í˜•íƒœì˜ ì‹ í˜¸ë¥¼ ì‚¬ìš©í•œë‹¤.

![image-20230720154304351]({{site.url}}/images/2023-07-19-BearingProject/image-20230720154304351.png){: .align-center}

ì‹¸ì¸ ì‹ í˜¸ì™€ Waveletì˜ ê°€ì¥ í° ì°¨ì´ëŠ” ì‹¸ì¸ ì‹ í˜¸ëŠ” ê·¸ ì˜ì—­ì´ ë¬´í•œí•œ ë°˜ë©´, Wavelet ê°™ì€ ê²½ìš° ì§€ì—­(íŠ¹ì • ì‹œê°„)ì— ëŒ€í•´ì„œ íŒŒí˜•ì„ ê°–ëŠ”ë‹¤. ì´ëŸ¬í•œ íŠ¹ì„± ë•Œë¬¸ì— í‘¸ë¦¬ì— ë³€í™˜ê³¼ ë‹¬ë¦¬ ì‹œê°„ì ì¸ íŠ¹ì„±ì„ ë°˜ì˜í•  ìˆ˜ ìˆë‹¤.

##### ğŸ“Waveletì˜ ì´ë¡ :

í‘¸ë¦¬ì— ë³€í™˜ ê°™ì€ ê²½ìš° ì‹¸ì¸ í˜•íƒœì˜ íŒŒí˜•ì„ í™œìš©í•˜ëŠ” ë°˜ë©´, Waveletì€ ì—¬ëŸ¬ í˜•íƒœì˜ Waveletì„ í™œìš©í•  ìˆ˜ ìˆë‹¤. í•´ë‹¹ Waveletì„ ë‹¤ í™œìš©í•´ ë³´ê³  ê·¸ ì¤‘ì—ì„œ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ê°’ì„ êµ¬í•´ë‚´ëŠ” Waveletì„ ì„ íƒí•˜ë©´ ëœë‹¤.

![image-20230721181614073]({{site.url}}/images/2023-07-19-BearingProject/image-20230721181614073.png){: .align-center}

ë‹¤ìŒì€ ë‹¤ì–‘í•œ í˜•íƒœì˜ waveletì„ ë‚˜íƒ€ë‚¸ë‹¤. ê°ê°ì˜ í˜•íƒœì˜ waveletì€ ë‹¤ë¥¸ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆì–´ ì í•©í•œ í™˜ê²½ì— í™œìš©ë  ìˆ˜ ìˆë‹¤.

íŒŒì´ì¬ì—ì„œ ì œê³µí•˜ê³  ìˆëŠ” wavelet ë¼ì´ë¸ŒëŸ¬ë¦¬ PyWaveletsì—ì„œëŠ” ì•„ë˜ì™€ ê°™ì€ ë‹¤ì–‘í•œ í˜•íƒœì˜ waveletì„ ì œê³µí•œë‹¤.

```python
import pywt
print(pywt.families(short=False))
['Haar', 'Daubechies', 'Symlets', 'Coiflets', 'Biorthogonal', 'Reverse biorthogonal',
'Discrete Meyer (FIR Approximation)', 'Gaussian', 'Mexican hat wavelet', 'Morlet wavelet',
'Complex Gaussian wavelets', 'Shannon wavelets', 'Frequency B-Spline wavelets', 'Complex Morlet wavelets']
```

Waveletì„ í™œìš©í•˜ì—¬ ì›ë³¸ ì‹ í˜¸ë¥¼ ë³€í˜•í•˜ëŠ” ê³¼ì •ì€ í¬ê²Œ ë‘ê°€ì§€ ê³¼ì •ì„ ê±°ì¹œë‹¤.

1.  Shifting
2.  Scaling

ì´ë‹¤.

Shifting- ì‹œê°„ì— ë”°ë¼ Waveletì„ ì´ë™ì‹œí‚¤ë©´ì„œ í•©ì„±ê³±ì„ í•˜ê²Œ ëœë‹¤. ì´ë¥¼ í†µí•´ ì‹œê°„ì„ ë°˜ì˜í•  ìˆ˜ ìˆê²Œ ëœë‹¤.

Scaling- ë™ì¼í•œ Waveletì„ ì›ë³¸ ì‹ í˜¸ì— ëŒ€í•˜ì—¬ í•©ì„±ê³±ì„ í•´ë„ ê·¸ í¬ê¸°ì— ë”°ë¼ ê°’ì´ ë‹¤ë¥´ë‹¤. CNNì„ ëŒë¦´ë•Œë„ Kernel ì‚¬ì´ì¦ˆì— ë”°ë¼ í•©ì„±ê³± ê²°ê³¼ê°’ì´ ë‹¬ë¼ì§€ëŠ” ê²ƒê³¼ ê°™ì´ Scalingì˜ í¬ê¸°ì— ë”°ë¼ Wavelet transformì˜ í¬ê¸°ê°€ ë‹¤ë¥´ë‹¤.

Fourier ë³€í™˜ì´ ì£¼ë¡œ ì£¼íŒŒìˆ˜ ì°¨ì›ìœ¼ë¡œ í‘œí˜„ëœë‹¤ë©´, Wavelet ë³€í™˜ì€ scale ì°¨ì›ìœ¼ë¡œ í‘œí˜„ëœë‹¤. scale ì°¨ì›ì„ ì£¼íŒŒìˆ˜ ì°¨ì›ìœ¼ë¡œ ë³€í˜•í•˜ê¸° ìœ„í•´ì„  Waveletì˜ ì¤‘ì‹¬ ì£¼íŒŒìˆ˜ì— scaleì„ ë‚˜ëˆ„ë©´ ì£¼íŒŒìˆ˜ë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤.

Fa = Fc/a

\*Fa = pseudo-frequency

\*Fc = central frequency of Mother wavelet

\*a = scale

í•´ë‹¹ ì‹ì— ë”°ë¥´ë©´, scale ê°’ì´ í´ìˆ˜ë¡(ê¸´ wavelet í˜•íƒœ) ì‘ì€ ì£¼íŒŒìˆ˜ ê°’ì„ êµ¬í•  ìˆ˜ ìˆëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

scale ê°’ì´ ì‘ìœ¼ë©´ ì§§ì€ í˜•íƒœì˜ waveletì´ ìƒì„±ë˜ê³  ê·¸ëŸ´ìˆ˜ë¡ ì‹œê°„ì˜ì—­ì—ì„œ ë” ì •ë°€í•œ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.

ë™ì¼í•œ Wavelet í˜•íƒœë„ ê³„ìˆ˜ì˜ ê°œìˆ˜ì™€ ë¶„í•´ë˜ëŠ” ì •ë„ì— ë”°ë¼ ë¶„ë¥˜ê°€ ë  ìˆ˜ ìˆë‹¤.

```python
import pywt
import matplotlib.pyplot as plt

db_wavelets = pywt.wavelist('db')[:5]
print(db_wavelets)
*** ['db1', 'db2', 'db3', 'db4', 'db5']

fig, axarr = plt.subplots(ncols=5, nrows=5, figsize=(20,16))
fig.suptitle('Daubechies family of wavelets', fontsize=16)
for col_no, waveletname in enumerate(db_wavelets):
    wavelet = pywt.Wavelet(waveletname)
    no_moments = wavelet.vanishing_moments_psi
    family_name = wavelet.family_name
    for row_no, level in enumerate(range(1,6)):
        wavelet_function, scaling_function, x_values = wavelet.wavefun(level = level)
        axarr[row_no, col_no].set_title("{} - level {}\n{} vanishing moments\n{} samples".format(
            waveletname, level, no_moments, len(x_values)), loc='left')
        axarr[row_no, col_no].plot(x_values, wavelet_function, 'bD--')
        axarr[row_no, col_no].set_yticks([])
        axarr[row_no, col_no].set_yticklabels([])
plt.tight_layout()
plt.subplots_adjust(top=0.9)
plt.show()
```

![image-20230721184056349]({{site.url}}/images/2023-07-19-BearingProject/image-20230721184056349.png){: .align-center}

ìœ„ ê·¸ë¦¼ì€ ë™ì¼í•œ 'Daubechies' í˜•íƒœì˜ Waveletì„ ë‚˜íƒ€ë‚¸ë‹¤. ì²«ë²ˆì§¸ ì—´ì€ db1, ë‘ë²ˆì§¸ ì—´ì€ db2, ì„¸ë²ˆì§¸ ì—´ì€ db3, ë„¤ë²ˆì§¸ ì—´ì€ db4ì´ë‹¤. db n í˜•íƒœì—ì„œ nì€ ì‚¬ë¼ì§€ëŠ” êµ¬ê°„ì˜ ìˆ˜ë¥¼ ì˜ë¯¸í•œë‹¤.

í–‰ë“¤ ê°„ì˜ ê´€ê³„ëŠ” ë¶„í•´ ì •ë„ë¥¼ ì˜ë¯¸í•œë‹¤.

ìœ„ ê·¸ë¦¼ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´ ì‚¬ë¼ì§€ëŠ” êµ¬ê°„ì˜ ìˆ˜ê°€ ì¦ê°€í•  ìˆ˜ë¡ ë¶„í•´ ì •ë„ëŠ” ì¦ê°€í•˜ê³  ê·¸ë˜í”„ëŠ” ë” ì™„ë§Œí•´ì§€ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

###### ğŸŒŸDWT

Waveletì€ ì—°ì†í˜•íƒœ í˜¹ì€ ì´ì‚°í˜•íƒœë¡œ ë‚˜íƒ€ë‚œë‹¤. í•´ë‹¹ ê¸€ì—ì„œëŠ” ì´ì‚°í˜•íƒœì¸ DWTë§Œ ë‹¤ë£¨ë„ë¡ í•˜ê² ë‹¤.

DWTëŠ” filter-bank í˜•íƒœë¡œ ì‹¤í–‰ëœë‹¤. ì—¬ê¸°ì„œ filter-bankì€ high-passì™€ low-pass filterë¥¼ í™œìš©í•˜ì—¬ ì‹ í˜¸ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì—¬ëŸ¬ê°€ì§€ì˜ ì£¼íŒŒìˆ˜ ë°´ë“œ í˜•íƒœë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.

DWTë¥¼ ì‹ í˜¸ì— ì ìš©í•  ë•Œ, ê°€ì¥ ì‘ì€ scale ê°’ì—ì„œ ë¶€í„° ì‹œì‘í•œë‹¤. Fa = Fc/a ì‹ì— ë”°ë¥´ë©´ scale ê°’ì´ ì‘ì„ìˆ˜ë¡ ì£¼íŒŒìˆ˜ ê°’ì´ ì»¤ì§€ë¯€ë¡œ ì²˜ìŒì— ê°€ì¥ ë†’ì€ ì£¼íŒŒìˆ˜ ê°’ì„ ë¶„ì„í•˜ëŠ” ê²ƒì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤. ë‘ë²ˆì§¸ ìŠ¤í…Œì´ì§€ì—ì„œëŠ” scale ê°’ì´ 2ë°° ì»¤ì§€ê²Œ ëœë‹¤. ë”°ë¼ì„œ ê°€ì¥ ë†’ì€ ì£¼íŒŒìˆ˜ì˜ ì ˆë°˜ì— í•´ë‹¹í•˜ëŠ” ê°’ì„ ë¶„ì„í•˜ê²Œ ëœë‹¤. ì´ëŸ°ì‹ì˜ ê³„ì‚°ì€ ìµœëŒ€ ë¶„í•´ ì •ë„ë¥¼ ë‹¤ë‹¤ë¥¼ë•Œê¹Œì§€ ì§„í–‰ëœë‹¤.

ì˜ˆë¥¼ ë“¤ìë©´, ì²˜ìŒ ì‹ í˜¸ì˜ ì£¼íŒŒìˆ˜ê°€ 1000Hzë¼ê³  í–ˆì„ ë•Œ, ì²«ë²ˆì§¸ stageì—ì„œëŠ” ì‹ í˜¸ë¥¼ low-frequency ë¶€ë¶„ê³¼(0-500Hz) high-frequency(500Hz-1000Hz) ë¶€ë¶„ìœ¼ë¡œ ë‚˜ë‰˜ê²Œ ëœë‹¤. ë‘ë²ˆì§¸ stageì—ì„œëŠ” low-frequency ë¶€ë¶„ì˜(0-500Hz)ë¥¼ 0-250Hzì™€ 250-500Hzë¡œ ë‚˜ë‰œë‹¤. ì´ëŸ°ì‹ìœ¼ë¡œ ì§„í–‰ë˜ë‹¤ ì‹ í˜¸ì˜ ê¸¸ì´ê°€ Waveletì˜ í¬ê¸° ë³´ë‹¤ ì‘ì•„ì§ˆ ë•Œê¹Œì§€ ì§„í–‰ëœë‹¤(ìµœëŒ€ ë¶„í•´ ì •ë„).

ì´ë¥¼ ì‹œê°í™”í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

```python
import pywt

x = np.linspace(0, 1, num=2048)
chirp_signal = np.sin(250 * np.pi * x**2)

fig, ax = plt.subplots(figsize=(6,1))
ax.set_title("Original Chirp Signal: ")
ax.plot(chirp_signal)
plt.show()

data = chirp_signal
waveletname = 'sym5'

fig, axarr = plt.subplots(nrows=5, ncols=2, figsize=(6,6))
for ii in range(5):
    (data, coeff_d) = pywt.dwt(data, waveletname)
    axarr[ii, 0].plot(data, 'r')
    axarr[ii, 1].plot(coeff_d, 'g')
    axarr[ii, 0].set_ylabel("Level {}".format(ii + 1), fontsize=14, rotation=90)
    axarr[ii, 0].set_yticklabels([])
    if ii == 0:
        axarr[ii, 0].set_title("Approximation coefficients", fontsize=14)
        axarr[ii, 1].set_title("Detail coefficients", fontsize=14)
    axarr[ii, 1].set_yticklabels([])
plt.tight_layout()
plt.show()

```

![image-20230721194641578]({{site.url}}/images/2023-07-19-BearingProject/image-20230721194641578.png){: .align-center}

ìœ„ ì½”ë”©ì„ í™•ì¸í•˜ë©´, DWTë¥¼ êµ¬í•˜ê¸° ìœ„í•´ pywt.dwt() í•¨ìˆ˜ê°€ ì‚¬ìš©ëœë‹¤. DWTëŠ” approximation coefficients, detail coefficient ë‘ê°€ì§€ ì¢…ë¥˜ì˜ ê³„ìˆ˜ë¥¼ ë°˜í™˜í•œë‹¤. approximation coefficientsëŠ” low pass filterì— í•´ë‹¹í•˜ê³  detail coefficientëŠ” high pass filterì— í•´ë‹¹í•œë‹¤. ê·¸ì „ ë‹¨ê³„ì˜ DWT ê°’ì„ ë‹¤ì‹œ ì ìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰ëœë‹¤.

###### ğŸ’”DWTë¥¼ í™œìš©í•œ ì‹ í˜¸ ë¶„í•´

ì§€ê¸ˆê¹Œì§€ DWTì˜ ì´ë¡ ì  ë°°ê²½ì„ ì•Œì•„ë³´ì•˜ë‹¤. ê·¸ëŸ¼ DWTê°€ ë² ì–´ë§ filteringì— ì–´ë–¤ì‹ìœ¼ë¡œ í™œìš©ë  ìˆ˜ ìˆì„ ê¹Œ?

í•´ë‹¹ ë°©ë²•ì€ ë”¥ëŸ¬ë‹ì—ì„œ Auto-encoderì‚¬ ì‚¬ìš©ë˜ëŠ” ë°©ë²•ê³¼ ìœ ì‚¬í•˜ë‹¤. pywt.dwt() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„í•´í•œ ì‹ í˜¸ë“¤ì„ ë‹¤ì‹œ ì›ë³¸ ì‹ í˜¸ë¥¼ íšŒìƒì‹œí‚¤ëŠ” ê³¼ì •ì—ì„œ ë¶ˆí•„ìš”í•œ ì‹ í˜¸ë“¤ì„ ì œê±°í•  ìˆ˜ ìˆë‹¤. ì—¬ê¸°ì„œ ë¶ˆí•„ìš”í•œ ì‹ í˜¸ëŠ” detail coefficientì— í•´ë‹¹í•œë‹¤. ì´ë¥¼ ì œê±°í•˜ëŠ” ê³¼ì •ì€ pywt.thresholdë¥¼ í™œìš©í•´ ì œê±°í•˜ëŠ” ë°©ì‹ì´ ìˆë‹¤.

NASA ë°ì´í„°ë¥¼ DWTë¡œ ì‹ í˜¸ë¥¼ ë¶„í•´í•œ í›„ ë‹¤ì‹œ ë³µêµ¬í•˜ëŠ” ê³¼ì •ì„ ì½”ë”©ì„ í•œ ê²ƒì´ë‹¤.

```python
DATA_FOLDER = './FEMTO_bearing/Training_set/Bearing1_1/'
filename = 'acc_01210.csv'
df = pd.read_csv(DATA_FOLDER + filename, header=None)
signal = df[4].values

def lowpassfilter(signal, thresh = 0.63, wavelet="db4"):
    thresh = thresh*np.nanmax(signal)
    coeff = pywt.wavedec(signal, wavelet, mode="per" )
    coeff[1:] = (pywt.threshold(i, value=thresh, mode="soft" ) for i in coeff[1:])
    reconstructed_signal = pywt.waverec(coeff, wavelet, mode="per" )
    return reconstructed_signal

fig, ax = plt.subplots(figsize=(12,8))
ax.plot(signal, color="b", alpha=0.5, label='original signal')
rec = lowpassfilter(signal, 0.4)
ax.plot(rec, 'k', label='DWT smoothing}', linewidth=2)
ax.legend()
ax.set_title('Removing High Frequency Noise with DWT', fontsize=18)
ax.set_ylabel('Signal Amplitude', fontsize=16)
ax.set_xlabel('Sample No', fontsize=16)
plt.show()
```

![image-20230721202757223]({{site.url}}/images/2023-07-19-BearingProject/image-20230721202757223.png){: .align-center}

###### â“ë§ì€ Wavelet ì¤‘ ì–´ë–¤ ê±¸ í™œìš©í•´ì•¼ í• ê¹Œ?

Waveletì€ ì •ë§ ë‹¤ì–‘í•œ í˜•íƒœì˜ íŒŒí˜•ì´ ìˆë‹¤. ì´ ì¤‘ ë¬¸ì œì— ì í•©í•œ waveletì„ ì°¾ëŠ” ê²ƒì´ ì£¼ìš”í•˜ë‹¤. ì´ë¥¼ ìœ„í•´ì„œëŠ” ì—¬ëŸ¬ wavelet íŒŒí˜• í˜•íƒœë¥¼ SVM classifierë¥¼ í†µí•´ ë¶„ë¥˜ë¥¼í•˜ê³  ê·¸ ì •í™•ë„ê°€ ê°€ì¥ ì¢‹ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì„ íƒí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•  ìˆ˜ ìˆë‹¤.

### ğŸ“£ ì´ìƒ ê°ì§€

#### ğŸŒ³ Isolation Forestë¥¼ ì´ìš©í•œ Anomaly detection

##### Isolation Forest ê°œë…:

Isolation ForestëŠ” ì´ìƒì¹˜ê°€ ì ê³  ë‹¤ë¥´ë‹¤ëŠ” ì ì—ì„œ ì°©ì•ˆ ëœ ê°œë…ì´ë‹¤. ì˜ì‚¬ê²°ì • ë‚˜ë¬´ë¥¼ ì§€ì†ì ìœ¼ë¡œ ë¶„ê¸°ì‹œí‚¤ë©´ì„œ ëª¨ë“  ë°ì´í„° ê´€ì¸¡ì¹˜ì˜ ê³ ë¦½ ì •ë„ ì—¬ë¶€ì— ë”°ë¼ ì´ìƒì¹˜ë¥¼ íŒë³„í•œë‹¤.

ë¶„ê¸° ë˜ëŠ” ê¹Šì´ê°€ ë‚®ì„ ìˆ˜ë¡ ì´ìƒì¹˜ì— ê°€ê¹ê³  ê¹Šì´ê°€ ë†’ì„ ìˆ˜ë¡ ì •ìƒ ë°ì´í„°ì— ê°€ê¹ë‹¤.

![isolationForest]({{site.url}}/images/2023-07-19-BearingProject/IsolationForest.png){: .align-center}

ì´ìƒì¹˜ëŠ” ë¶„ê¸°ë˜ëŠ” ê¹Šì´ê°€ ì–•ë‹¤.

![isolationForest2]({{site.url}}/images/2023-07-19-BearingProject/IsolationForest2.png){: .align-center}

ì •ìƒ ë°ì´í„°ëŠ” ë¶„ê¸°ë˜ëŠ” ê¹Šì´ê°€ ê¹Šë‹¤.

##### Isolation Forest ì•Œê³ ë¦¬ì¦˜:

1. ë¬´ì‘ìœ„ ë°ì´í„°ê°€ ì£¼ì–´ì§ˆ ë•Œ ë°ì´í„°ì˜ ìƒ˜í”Œì´ ì´ì§„ ë¶„ë¥˜ íŠ¸ë¦¬ì— í• ë‹¹ëœë‹¤.

2. ì´ì§„ ë¶„ë¥˜ëŠ” ëœë¤í•œ í”¼ì³ë¥¼ ì„ íƒí•˜ëŠ” ê±¸ë¡œ ì‹œì‘í•œë‹¤. ëœë¤í•œ í”¼ì³ê°€ ì„ íƒë˜ë©´ ì„ íƒëœ í”¼ì³ì—ì„œ ëœë¤í•œ ê°’ì„ ì„ íƒí•˜ì—¬ thresholdë¡œ ì„ ì •í•œë‹¤.

3. ë°ì´í„° í¬ì¸íŠ¸ê°€ threshold ë³´ë‹¤ ì‘ì„ ê²½ìš° ì™¼ìª½ branchë¡œ ë“¤ì–´ê°„ë‹¤. thresholdê°€ í´ ê²½ìš° ì˜¤ë¥¸ìª½ branchë¡œ ë“¤ì–´ê°„ë‹¤.

4. ì‚¬ìš©ìê°€ ì§€ì •í•´ì¤€ ê¹Šì´ë‚˜ ë°ì´í„°ê°€ ì™„ì „ ê´´ë¦½ë  ë•Œê¹Œì§€ 2ë²ˆ ê³¼ì •ì„ ë°˜ë³µí•œë‹¤.

ì´ìƒì¹˜(anomaly)ì— í•´ë‹¹í•˜ëŠ” ê°’ì€ anomaly score -1ì„ ê°–ê²Œ ë˜ê³  ì •ìƒ ë°ì´í„° ê°™ì€ ê²½ìš° 1ì„ ê°–ê²Œ ëœë‹¤.

##### Isolation Forest Python ì½”ë“œ:

```python

```

#### ğŸ“ ABODë¥¼ í™œìš©í•œ ì´ìƒê°ì§€

ABOD(Angle-based Outlier Detection)ì€ ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ì´ìƒì¹˜ë¥¼ ê°ì§€í•  ë•Œ ìœ ìš©í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ì´ë‹¤.

##### ABOD ê°œë…:

ë‹¤ë³€ëŸ‰ ë°ì´í„°ì—ì„œ ì„ì˜ì˜ 3ê°œì˜ ë°ì´í„°ê°€ ìƒì„±í•˜ëŠ” ê°ë„ë¥¼ ë©´ë°€íˆ ê´€ì°°í•˜ëŠ” ê²ƒì´ ABODì˜ í•µì‹¬ ê°œë…ì´ë‹¤. í•´ë‹¹ ê°ë„ì˜ ë¶„ì‚°ì€ ì´ìƒì¹˜ì™€ ì •ìƒì¹˜ê°€ ë‹¤ë¥´ê²Œ ë‚˜íƒ€ë‚œë‹¤. ë³´í†µì˜ ê²½ìš°, ì •ìƒì¹˜ì˜ ê°ë„ ë¶„ì‚° ê°’ì´ ì´ìƒì¹˜ì— ë¹„í•´ ë” í¬ê²Œ ë‚˜íƒ€ë‚œë‹¤ ABODëŠ” ë‹¤ë¥¸ ë¨¸ì‹ ëŸ¬ë‹ ì´ìƒíƒì§€ ê¸°ë²•ê³¼ ë‹¬ë¦¬, ê³ ì°¨ì›ì—ì„œë„ ê°ì§€ë¥¼ ì˜í•œë‹¤ëŠ” íŠ¹ì§•ì´ ìˆë‹¤.

![ABOD.png]({{site.url}}/images/2023-07-19-BearingProject/ABOD.png)

##### ABOD ì•Œê³ ë¦¬ì¦˜:

1. ê°ê°ì˜ ë°ì´í„°ë“¤ì— ëŒ€í•´ì„œ ì¡°í•©ì„ ìƒì„±í•œ í›„ í•´ë‹¹ ì¡°í•©ì´ ë§Œë“¤ì–´ë‚´ëŠ” ê°ë„ë¥¼ ê°ë„ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥í•œë‹¤.
2. í•´ë‹¹ ë¦¬ìŠ¤íŠ¸ì—ì„œ ë§Œë“¤ì–´ì§„ ê°ë„ì˜ ë¶„ì‚° ê°’ì„ êµ¬í•œë‹¤.
3. íŠ¹ì • ì„ê³„ê°’ ì´í•˜ì˜ ê°’ì€ ì´ìƒì¹˜ë¡œ ë¶„ë¥˜í•œë‹¤.

##### ì´ìƒ ê°ì§€ë¥¼ ìœ„í•œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë“ˆ pyod:

```python
def outliers_detection(model, name):
    clf = model
    clf.fit(Y)

    outliers = clf.predict(Y)

    Y_outliers = Y[np.where(outliers==1)]
    X_outliers = X[np.where(outliers==1)]

    Y_inliers = Y[np.where(outliers==0)]
    X_inliers = X[np.where(outliers==0)]
    print(X_outliers)


    plt.scatter(X_outliers, Y_outliers, edgecolor='black',color='red', label='outliers')
    plt.scatter(X_inliers, Y_inliers, edgecolor='black',color='green', label='inliers')
    plt.title(name)
    plt.legend()
    plt.grid()
    plt.ylabel('Y')
    plt.xlabel('X')
    plt.show()

    anomaly_score = clf.decision_function(Y)
    min_outlier_anomaly_score = np.floor(np.min(anomaly_score[np.where(outliers==1)])*10)/10
    plt.hist(anomaly_score, bins=n_bins)
    plt.axvline(min_outlier_anomaly_score, c='k')
    plt.xlabel('Anomaly Score')
    plt.ylabel('Number of data points')
    plt.show()
    return anomaly_score
```

pyodëŠ” ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ë“¤ì„ ì œê³µí•˜ê³  í•´ë‹¹ ì‹ì„ í™œìš©í•˜ë©´ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.

##### ABOD Python ì½”ë“œ(pyodë¥¼ í™œìš©í•œ ì½”ë“œ):

```python

from pyod.models.abod import ABOD
clf = ABOD()
clf.fit(X_train)

#get outliers scores
y_train_scores = clf.decision_scores_#íŠ¸ë ˆì¸ ë°ì´í„°ì— ëŒ€í•œ outlier scoreë¥¼ êµ¬í•œë‹¤
y_test_scores = clf.decision_function(X_test)#í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ outlier scoreì„ êµ¬í•œë‹¤.

```

##### Fast ABOD ê°œë…:

ABODëŠ” êµ‰ì¥íˆ ì¢‹ì€ ì´ìƒê°ì§€ ì•Œê³ ë¦¬ì¦˜ì´ë‚˜ ì‹œê°„ ë³µì¡ë„ê°€ O(n^3)ì´ ë  ë§Œí¼ ì‹œê°„ì´ ë§ì´ ê±¸ë¦¬ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë‹¤. ì´ë¥¼ ê°œì„ í•œ ê²ƒì´ Fast ABODì´ë‹¤. Fast ABODëŠ” ëª¨ë“  ì ë“¤ì— ëŒ€í•´ ê°€ëŠ¥í•œ ëª¨ë“  ì¡°í•©ì„ ì°¾ëŠ” ëŒ€ì‹ ì— KNN(K-nearest neighbor)ë¥¼ í™œìš©í•˜ì—¬ ë¶„ì‚° ê°’ì„ ì¶”ì •í•œë‹¤.

#### Mahalanobis ê±°ë¦¬ì™€ MCDë¥¼ ì´ìš©í•œ ì´ìƒê°ì§€

##### Mahalanobis ê±°ë¦¬

###### [ìœ í´ë¦¬ë“œ ê±°ë¦¬]

ë°ì´í„° ë¶„í¬ì—ì„œ ë°ì´í„° ê°„ì˜ ê±°ë¦¬ë¥¼ êµ¬í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì€ ë‹¤ì–‘í•˜ê²Œ ìˆë‹¤. ì´ ì¤‘ì—ì„œ ìš°ë¦¬ê°€ í”íˆ ì¤‘, ê³ ë“±í•™êµ ë•Œ ë°°ì› ë˜ ê±°ë¦¬ë¥¼ êµ¬í•˜ëŠ” ë°©ì‹ì€ ìœ í´ë¦¬ë“œ ê±°ë¦¬ì´ë‹¤.

![uclidean.png]({{site.url}}/images/2023-07-19-BearingProject\ìœ í´ë¦¬ë””ì•ˆê±°ë¦¬.png)

í”íˆ ìˆ˜í•™ ì‹œê°„ì— ë°°ìš´ ë‘ ì§€ì ì˜ ê±°ë¦¬ë¥¼ êµ¬í•˜ëŠ” ê³µì‹ì´ë‹¤. ì´ë¥¼ ë²¡í„°ì˜ ê´€ì ì—ì„œ ìƒê°ì„ í•´ë³´ë©´, ë‘ ë²¡í„°ì˜ ë‚´ì ìœ¼ë¡œ ê±°ë¦¬ë¥¼ í‘œí˜„í•œ ê²ƒì´ë¼ê³ ë„ ìƒê°í•  ìˆ˜ ìˆë‹¤.

ì´ëŸ¬í•œ ìœ í´ë¦¬ë“œ ê±°ë¦¬ì˜ ë‹¨ì ì€ ë§¥ë½(í˜¹ì€ ê´€ê³„?)ì„ íŒŒì•…í•˜ì§€ ëª»í•œë‹¤ëŠ” ì ì´ë‹¤. ë§¥ë½ì„ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ë¥¼ ì´í•´í•˜ë©´ ëœë‹¤.

###### [ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬]

ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ëŠ” ìœ í´ë¦¬ë“œ ê±°ë¦¬ê°€ ê³ ë ¤í•˜ì§€ ëª»í•˜ëŠ” "ë§¥ë½"ì„ ê³ ë ¤í•˜ì—¬ ê±°ë¦¬ë¥¼ ì¬ëŠ” ë°©ì‹ì´ë‹¤. ì—¬ê¸°ì„œ ë§¥ë½ì´ë€ ë¬´ìŠ¨ ëœ»ì¼ê¹Œ? ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ì—ì„œ "ë§¥ë½"ì€ ë°ì´í„° ë¶„í¬ë¥¼ ì˜ë¯¸í•œë‹¤. ì¦‰, ë‹¤ë³€ëŸ‰ ë°ì´í„°ì—ì„œ ë¶„í¬ì˜ í˜•íƒœë¥¼ ê³ ë ¤í•˜ì—¬ ê±°ë¦¬ë¥¼ ì¬ê² ë‹¤ëŠ” ì´ë¡ ì´ë‹¤.

![uclidean_distance.png]({{site.url}}/images/2023-07-19-BearingProject\ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ê±°ë¦¬.png)

ìœ„ ì‹ì—ì„œ ë…¸ë€ìƒ‰ìœ¼ë¡œ ì¹ í•´ì§„ ë¶€ë¶„ì€, ê³µë¶„ì‚° í–‰ë ¬ë¡œ ë³€ìˆ˜ë“¤ê°„ì˜ Correlationì„ ê³ ë ¤í•˜ê² ë‹¤ëŠ” ê²ƒì´ë‹¤. í•´ë‹¹ ì‹ì—ì„œ ë¶„ì‚°ì´ 1ë¡œ ì •ê·œí™” ë˜ê³  ë³€ìˆ˜ë“¤ì´ ì„œë¡œ ë…ë¦½ì¼ ê²½ìš°, ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ì™€ ê°™ì•„ì§„ë‹¤.

ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ë¥¼ ì‹œê°í™” í•˜ë©´,

![uclidean_distance_graph.png]({{site.url}}/images/2023-07-19-BearingProject\ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ê±°ë¦¬_ë¶„í¬.png)

ìœ„ ê·¸ë¦¼ì„ ë³´ë©´, ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ë¡œ íŒë‹¨í•˜ì˜€ì„ ê²½ìš°, yì¶•ì— ìˆëŠ” ë³„ì´ xì¶•ì— ìˆëŠ” ë³„ë³´ë‹¤ ê°€ê¹Œì´ ìˆëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ì§€ë§Œ, ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ì—ì„œëŠ” xì¶•ì— ìˆëŠ” ë³„ì´ yì¶•ì— ìˆëŠ” ë³„ë³´ë‹¤ ê°€ê¹Œì´ ìˆë‹¤.

ë“±ê³ ì„ ì„ ê³ ë ¤í–ˆì„ ë•Œ, x ì¶•ì— ìˆëŠ” ë³„ì´ y ì¶•ì— ìˆëŠ” ë³„ë³´ë‹¤ ë“±ê³ ì„  ìƒ ê°€ê¹Œì´ ìœ„ì¹˜í•˜ê¸° ë–„ë¬¸ì´ë‹¤.

##### MCD

ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ëŠ” ë³€ìˆ˜ë“¤ê°„ì˜ ê³µë¶„ì‚° ê°’ì„ êµ¬í•˜ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì— ì œê³±ì„ ì·¨í•˜ê²Œ ëœë‹¤. í•˜ì§€ë§Œ ì œê³±ì„ ì·¨í•  ì‹œ, outlierë¥¼ êµ¬í•˜ëŠ” ë° êµ‰ì¥íˆ ì·¨ì•½í•´ì§ˆ ìˆ˜ ë°–ì— ì—†ë‹¤. ì´ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•œ ë°©ë²•ì´ ë°”ë¡œ MCDì´ë‹¤.

##### MCD Python ì½”ë“œ:

```python
from pyod.models.mcd import MCD

...

```

#### OC-SVM(One-Class SVM)

OC-SVMì„ ì´í•´í•˜ê¸° ìœ„ìƒˆì„œëŠ” ê¸°ë³¸ì ì¸ SVM ê°œë…ì„ ì•Œì•„ì•¼í•œë‹¤. SVM ê°œë…ì€ ë‹¤ìŒ ë¸”ë¡œê·¸ì— ì˜ ë‚˜ì™€ ìˆìœ¼ë‹ˆ ì°¸ê³ í•˜ë„ë¡ í•˜ì.

##### SVM ê°œë…:

[SVM ê°œë…](https://losskatsu.github.io/machine-learning/svm/#%EB%84%88%EB%B9%84width-%EC%B5%9C%EB%8C%80%ED%99%94)

##### OC-SVM ê°œë…:

OC-SVM ê°œë… ë˜í•œ í•´ë‹¹ ë¸”ë¡œê·¸ì— ì˜ ë‚˜ì™€ìˆë‹¤. ìì„¸í•œ ìˆ˜í•™ì ì¸ ì¦ëª…ì„ ì•Œê³  ì‹¶ìœ¼ë©´ í•´ë‹¹ ë¸”ë¡œê·¸ë¥¼ ì°¸ê³ í•˜ì.

[OC-SVM](https://losskatsu.github.io/machine-learning/oneclass-svm/#2-one-class-svm%EC%9D%98-%EB%AA%A9%EC%A0%81)

SVMì˜ ìˆ˜í•™ì  ì˜ë¯¸ë¥¼ ì•Œê³  ì‹¶ìœ¼ë©´ ìœ„ ë¸”ë¡œê·¸ë¥¼ ì°¸ê³ í•˜ë„ë¡ í•˜ê³ , ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•˜ê²Œ ê°œë…ì— ëŒ€í•´ ë„˜ì–´ê°€ë„ë¡ í•˜ê² ë‹¤.

ì§€ë„í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” SVMì€ ë³´í†µ ë¼ë²¨ë§ì´ ë˜ì–´ ìˆëŠ” ë°ì´í„°ë¥¼ ì„œí¬íŠ¸ ë²¡í„°ë¥¼ ì´ìš©í•´ ë¶„ë¥˜í•˜ëŠ” ê²ƒì´ë‹¤.

OC-SVM(One Class SVM) ê°™ì€ ê²½ìš°, ì§€ë„ í•™ìŠµì´ ì•„ë‹Œ ë¹„ì§€ë„ í•™ìŠµ í˜•íƒœì˜ SVMì´ë‹¤.

OC-SVMì˜ ëª©ì ì€ ë¼ë²¨ë§ì´ ë˜ì–´ ìˆì§€ ì•Šì€ ë°ì´í„°ë“¤ì„ ê°€ì§€ê³  ì •ìƒ ë°ì´í„°ì™€ ë¹„ì§€ë„ í•™ìŠµìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì´ë‹¤. ì´ë¥¼ ìœ„í•´ì„œ OC-SVMì€ ì´ˆí‰ë©´ì„ ìƒì„±í•˜ê³  ì´ˆí‰ë©´ê³¼ ì´ìƒì¹˜ì™€ì˜ ê±°ë¦¬ê°€ ìµœëŒ€ê°€ ë  ìˆ˜ ìˆë„ë¡ í•˜ì—¬ ì •ìƒê³¼ ì´ìƒì¹˜ë¥¼ êµ¬ë¶„í•œë‹¤.

![OC-SVM_1]({{site.url}}/images/2023-07-19-BearingProject/oc-svm_1.png){: .align-center}

ìœ„ ê·¸ë¦¼ì— ìˆëŠ” ë¹¨ê°„ìƒ‰ ì„ ì´ ì´ˆí‰ë©´ì´ê³ , ì´ˆí‰ë©´ì„ ê¸°ì¤€ìœ¼ë¡œ ì™¼ìª½ì— ìˆëŠ” ê°’ì€ ì´ìƒì¹˜ì´ê³ , ì˜¤ë¥¸ìª½ì— ìˆëŠ” ë°ì´í„° ê°’ì€ ì •ìƒì¹˜ì´ë‹¤. ë¹¨ê°„ìƒ‰ ì„ ì—ì„œ ë¶€í„° ì´ìƒì¹˜ê¹Œì§€ì˜ ê±°ë¦¬ë¥¼ Eië¼ê³  í•˜ì, ì´ë•Œ ì •ìƒì¹˜ëŠ” ì´ìƒì¹˜ê°€ ì•„ë‹ˆë¯€ë¡œ Ei ê°’ì€ 0ì´ ëœë‹¤.

ìš°ë¦¬ëŠ” ì´ Ei ê°’ì„ ìµœëŒ€ë¡œ í•˜ê²Œ í•˜ë©´ ëœë‹¤.

![OC-SVM]({{site.url}}/images/2023-07-19-BearingProject/oc-svm.png){: .align-center}

ìœ„ ê·¸ë¦¼ì„ ë³´ë©´, WëŠ” ì›ì ì—ì„œ ì´ˆëª…ë©´ê°„ì˜ ìˆ˜ì§ ë²¡í„°ë¥¼ ì˜ë¯¸í•˜ê³ , XiëŠ” ì´ìƒì¹˜ì™€ ì›ì ê°„ì˜ ë²¡í„°ë¥¼ ì˜ë¯¸í•œë‹¤. ì´ìƒì¹˜ ê°™ì€ ê²½ìš° W ë²¡í„°ì™€ ì´ìƒì¹˜ê°„ì˜ ë‚´ì  ê°’ì´ ì´ˆí‰ë©´ì„ ë„˜ì–´ê°€ì§€ ëª»í•œë‹¤.

ë°˜ë©´ ì´ˆí‰ë©´ ì˜¤ë¥¸ìª½ì— ìœ„ì¹˜í•˜ëŠ” ì •ìƒ ë°ì´í„° ê°™ì€ ê²½ìš° W ë²¡í„°ì™€ ì´ìƒì¹˜ ê°„ì˜ ë‚´ì  ê°’ì´ ì´ˆí‰ë©´ì„ ë„˜ê²Œ ëœë‹¤.

ê·¸ë¦¬ê³  Wë²¡í„°ì™€ ì´ìƒì¹˜ì˜ ë‚´ì  ê°’ì´ ì›ì ì—ì„œ ì´ˆí‰ë©´ê¹Œì§€ì˜ ê±°ë¦¬ Pì—ì„œ ì´ˆí‰ë©´ì—ì„œ ì´ìƒì¹˜ê¹Œì§€ì˜ ê±°ë¦¬ì™€ ê°™ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

ì´ë¥¼ ìµœì í™” í‘œí˜„ìœ¼ë¡œ ë°”ê¾¸ë©´,

![OC-SVM_2]({{site.url}}/images/2023-07-19-BearingProject/oc-svm_2.png){: .align-center}

ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤. ì‹ì„ ì˜ ë³´ë©´, êµ¬í•˜ê³ ì í•˜ëŠ” ê²ƒì´ P-Eiê°’ì˜ ìµœëŒ€ê°’ì´ì—ˆëŠ” ë° ì´ë¥¼ ë¶€í˜¸ë¥¼ ë°”ê¾¸ê³  ìµœì†Ÿê°’ì„ êµ¬í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í–ˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

##### oc-svm íŒŒì´ì¬ ì½”ë“œ Pyod

pyodëŠ” oc-svm ê¸°ëŠ¥ ë˜í•œ ì œê³µí•œë‹¤.

```python
from from pyod.models.ocsvm import OCSVM

```

#### DeepSVDDë¥¼ ì´ìš©í•œ ì´ìƒê°ì§€

í•´ë‹¹ ê°œë…ì€ ì•„ë˜ ë§í¬ë¥¼ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.

[DeepSVDD ê°œë…](https://ffighting.net/deep-learning-paper-review/anomaly-detection/deep-svdd/)

##### SVDD ê°œë…:

SVDDëŠ” ì •ìƒ ë°ì´í„°ë“¤ë§Œì„ í¬í•¨í•˜ëŠ” í•˜ë‚˜ì˜ êµ¬ë¥¼ ì°¾ì•„ë‚´ê³  ê·¸ê²ƒì— ë²—ì–´ë‚œ ê°’ë“¤ì„ ë‹¤ ì´ìƒì¹˜ë¡œ íŒë‹¨í•˜ëŠ” ë°©ë²•ì´ë‹¤. í•´ë‹¹ êµ¬ì—ì„œ ë§ì´ ë²—ì–´ë‚˜ ìˆì„ìˆ˜ë¡ ë¹„ì •ìƒ ë°ì´í„°ë¼ê³  íŒë‹¨í•˜ëŠ” ê²ƒì´ë‹¤.

![SVDD]({{site.url}}/images/2023-07-19-BearingProject/svdd_ë¬¸ì œì .png){: .align-center}

í•˜ì§€ë§Œ SVDDëŠ” ìœ„ ê·¸ë¦¼ê³¼ ê°™ì€ ìƒí™©ì¼ ë•Œ í•œê³„ê°€ ìˆë‹¤. ìœ„ ê·¸ë¦¼ì—ì„œ íŒŒë€ìƒ‰ í° ì›ì€ ì •ìƒ ë°ì´í„°ë¥¼ í¬í•œí•˜ëŠ” êµ¬ì´ë‹¤. ì´ë•Œ X1, X2 ë‘ ì ì„ ë³´ë©´, X1 ê°™ì€ ê²½ìš° ì •ìƒ ë°ì´í„°ë¼ê³  í•  ìˆ˜ ìˆëŠ” ë²”ìœ„ì— ìˆìœ¼ë‚˜, X2 ê°™ì€ ê²½ìš° ì •ìƒ ë°ì´í„°ë¼ê³  í•˜ê¸´ ì–´ë µë‹¤. í•˜ì§€ë§Œ SVDDë¥¼ ì‚¬ìš©í•  ì‹œ ê·¸ëŒ€ë¡œ ì •ìƒìœ¼ë¡œ íŒë‹¨í•˜ê²Œ ëœë‹¤.

ì´ë¥¼ ë³´ì™„í•˜ê³ ì í•˜ëŠ” ê²ƒì´ Deep SVDDì´ë‹¤.

##### DeepSVDD:

ìœ„ SVDDê°€ ê°€ì§€ê³  ìˆëŠ” í•œê³„ì— ëŒ€í•´ ìƒê°ì„ í•´ë³´ì, ì •ìƒ ë°ì´í„° êµ¬ì— í¬í•¨ë˜ë‚˜ ë¹„êµì  ì •ìƒ ë°ì´í„° í´ëŸ¬ìŠ¤í„°ì™€ ë©€ë¦¬ ìˆëŠ” ê°’ ê°™ì€ ê²½ìš°ë¥¼ ë‹¤ë£° ìˆ˜ ì—†ëŠ” ê²Œ SVDDì˜ í•œê³„ì´ë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê³ ì•ˆí•œ ë°©ë²•ì´, CNNì„ í™œìš©í•˜ì—¬ ë„“ê²Œ ë¶„í¬ëœ ë°ì´í„°ë¥¼ ëª¨ì•„ì£¼ëŠ” ë°©ë²•ì´ë‹¤.

![Deep_SVDD]({{site.url}}/images/2023-07-19-BearingProject/Deep_svdd.png){: .align-center}

CNNì„ ì‚¬ìš©í•˜ì—¬ ì •ìƒ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì €ì°¨ì›ì˜ feature ê³µê°„ìœ¼ë¡œ ë§¤í•‘í•  ê²ƒì´ë‹¤. ì´ë•Œ ë§¤í•‘í•˜ëŠ” ë°©í–¥ì€ ëª¨ë“  ì •ìƒ ì´ë¯¸ì§€ì˜ featureë“¤ì´ í•œ ì ì„ ì¤‘ì‹¬ìœ¼ë¡œ ëª¨ì´ë„ë¡ í•œë‹¤.

![Deep_SVDD_cnn]({{site.url}}/images/2023-07-19-BearingProject/deep_svdd_cnn.png){: .align-center}

CNNì´ ê³ ì°¨ì›ì˜ ê³µê°„ì„ ì €ì°¨ì›ì˜ ê³µê°„ìœ¼ë¡œ ë§¤í•‘ í•´ì¤„ ìˆ˜ ìˆëŠ” ì„±ì§ˆì„ ì´ìš©í•œ ê²ƒì…ë‹ˆë‹¤.

![Deep_SVDD_cnn_1]({{site.url}}/images/2023-07-19-BearingProject/cnn_deep.png){: .align-center}

##### DeepSVDD íŒŒì´ì¬ ì½”ë“œ Pyod:

```python
from pyod.models.deep_svdd import DeepSVDD

...

```

#### VAEë¥¼ í™œìš©í•œ ì´ìƒê°ì§€

##### VAEì™€ AEì˜ ì°¨ì´ì :

VAEëŠ” Variational Auto-Encoderì˜ ì•½ìë¡œ ì´ë¦„ë§Œ ë´ì„œëŠ” Auto-Encoderì™€ ë¹„ìŠ·í•œ ê°œë…ì´ë¼ ìƒê°ì´ ë“¤ì§€ë§Œ ì „í˜€ ë‹¤ë¥¸ ê°œë…ì´ë‹¤.

ë‹¤ìŒ ë§í¬ë¥¼ ì°¸ê³ í•˜ì˜€ë‹¤. [VAE\_ë¸”ë¡œê·¸](https://chickencat-jjanga.tistory.com/3)

AE:

![AE]({{site.url}}/images/2023-07-19-BearingProject/vae-autoencoder.png){: .align-center}

Auto Encoderì˜ ëª©ì ì€ Encoderì— ìˆë‹¤. AEëŠ” Encoderì˜ í•™ìŠµì„ ìœ„í•´ Decoderë¥¼ ë¶™ì¸ ê²ƒì´ë‹¤.

latent vectorê°€ ì–´ë–¤ í•˜ë‚˜ì˜ ê°’ì„ ê°€ì§€ê²Œ ëœë‹¤.

VAE:

![VAE]({{site.url}}/images/2023-07-19-BearingProject/vae_1.png){: .align-center}

Variational AutoEncoderì˜ ëª©ì ì€ Decoderì— ìˆë‹¤. Decoderì˜ í•™ìŠµì„ ìœ„í•´ Encoderë¥¼ ë¶™ì¸ ê²ƒì´ë‹¤.

ì¶”ì¶œëœ latent vectorì˜ ê°’ì„ í•˜ë‚˜ì˜ ìˆ«ìë¡œ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ê°€ìš°ì‹œì•ˆ í™•ë¥  ë¶„í¬ì— ê¸°ë°˜í•œ í™•ë¥ ê°’ìœ¼ë¡œ ë‚˜íƒ€ë‚´ê²Œ ëœë‹¤.

![VAE_2]({{site.url}}/images/2023-07-19-BearingProject/vae_2.png){: .align-center}

##### VAEì˜ ê°œë…:

VAEëŠ” Input image Xë¥¼ ì˜ ì„¤ëª…í•˜ëŠ” featureë¥¼ ì¶”ì¶œí•˜ì—¬ Latent vector zì— ë‹´ê³ , ì´ Latent vector zë¥¼ í†µí•´ Xì™€ ìœ ì‚¬í•˜ì§€ë§Œ ì™„ì „íˆ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„±í•´ë‚´ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.

âœ” ì´ë•Œ ì¶”ì¶œë˜ëŠ” featureëŠ” ê°€ìš°ì‹œì•ˆ ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ê³  ê°€ì •í•œë‹¤

âœ” Latent vector zëŠ” ê° featureì˜ í‰ê· ê³¼ ë¶„ì‚°ê°’ì„ ë‚˜íƒ€ë‚¸ë‹¤

âœ” AEì˜ decoderì²˜ëŸ¼ latent vectorë¡œë¶€í„° ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ë‚¸ë‹¤ê³  ë³´ë©´ ëœë‹¤. í•˜ì§€ë§Œ AEì™€ ë‹¤ë¥¸ ì ì€ latent vectorì— ìˆëŠ” ê°’ì´ ê°’ì´ ì•„ë‹ˆë¼ í™•ë¥  ê°’ì´ë¼ëŠ” ì ì´ë‹¤.

ì˜ˆë¥¼ ë“¤ì–´, ì‹œì¸„ ì–¼êµ´ì„ ê·¸ë¦¬ê³ ì í•œë‹¤ë©´, ì‹œì¸„ì˜ ëˆˆ, ì½”, ì… ë“±ì˜ featureë¥¼ í‰ê·  ë° ë¶„ì‚° í˜•íƒœë¡œ Latent vector zì— ë‹´ê³ , ê·¸ zë¥¼ ì´ìš©í•´ ì‹œì¸„ì˜ ì–¼êµ´ì„ ê·¸ë¦¬ê²Œ ëœë‹¤.

VAEì˜ êµ¬ì¡°ë¥¼ ë„ì‹í™” í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

![VAE_3]({{site.url}}/images/2023-07-19-BearingProject/vae_êµ¬ì¡°.png){: .align-center}

VAEëŠ” Input Imageê°€ ë“¤ì–´ì˜¤ë©´, ê·¸ ì´ë¯¸ì§€ì—ì„œì˜ ë‹¤ì–‘í•œ íŠ¹ì§•ë“¤ì´ ê°ê°ì˜ í™•ë¥  ë³€ìˆ˜ê°€ ë˜ëŠ” ì–´ë–¤ í™•ë¥  ë¶„í¬ë¥¼ ë§Œë“¤ê²Œ ëœë‹¤. ì´ëŸ° í™•ë¥  ì¤‘ì—ì„œ í™•ë¥ ê°’ì´ ë†’ì€ ë¶€ë¶„ì„ ì´ìš©í•˜ë©´ ì‹¤ì œì— ìˆì„ë²•í•œ ì´ë¯¸ì§€ë¥¼ ìƒˆë¡­ê²Œ ë§Œë“¤ ìˆ˜ ìˆë‹¤.

![VAE_4]({{site.url}}/images/2023-07-19-BearingProject/vae_í™•ë¥ ë„ì‹.png){: .align-center}

##### VAEë¥¼ ì´ìš©í•œ ì´ìƒê°ì§€:

ì, ì´ì œ VAEì˜ ê°œë…ì„ ì•Œì•„ë´¤ìœ¼ë‹ˆ, VAEê°€ ì´ìƒê°ì§€ì— ì–´ë–»ê²Œ ì‚¬ìš©ë˜ëŠ”ì§€ ì•Œì•„ë´ì•¼ í•œë‹¤. VAEëŠ” AEê°€ ì´ìƒê°ì§€ì— ì‚¬ìš©ë˜ëŠ” ë°©ì‹ê³¼ ë™ì¼í•œ ì›ë¦¬ë¡œ ì‚¬ìš©ëœë‹¤.

ìš°ì„  AEë¥¼ í™œìš©í•œ ì´ìƒê°ì§€ì— ì›ë¦¬ë¥¼ ì‚´í´ë³´ì. Auto EncoderëŠ” Encoderì™€ Decoderë¡œ ë‚˜ëˆ ì ¸ìˆë‹¤. Encoder ê°™ì€ ê²½ìš°, ì…ë ¥ ê°’ì˜ íŠ¹ì§•ì„ ê°’ í˜•íƒœë¡œ ë³€í™˜í•œë‹¤. ë³€í™˜ëœ ê°’ì„ í†µí•´ Decoderë¡œ ë³µì›ì„ í•œë‹¤. ì •ìƒì¹˜ê°€ Encoderì— ë“¤ì–´ê°€ ìƒê¸°ëŠ” ê°’ê³¼ ì´ìƒì¹˜ê°€ Encoderì— ë“¤ì–´ê°€ ìƒê¸°ëŠ” ê°’ì´ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ë³µì›ì‹œ ì •ìƒì¹˜ì™€ ì´ìƒì¹˜ê°€ ë‹¤ë¥´ê²Œ ë‚˜íƒ€ë‚˜ê²Œ ëœë‹¤. AEë¥¼ ì´ìƒê°ì§€ì— í™œìš©í•  ë•ŒëŠ” ì´ëŸ¬í•œ ë°©ë²•ì„ ì‚¬ìš©í•œë‹¤.

VAEë„ ê°™ì€ ì›ë¦¬ë¡œ ì´ìƒê°ì§€ì— í™œìš©ëœë‹¤. ì •ìƒì¹˜ì™€ ì´ìƒì¹˜ê°€ Encoderì— ë“¤ì–´ê°€ë©´ latent vectorì— ì„œë¡œ ë‹¤ë¥¸ í˜•íƒœì˜ í™•ë¥  ë¶„í¬ë¥¼ ê°–ê²Œë˜ê³  ì´ë¥¼ ë‹¤ì‹œ Decoderë¥¼ í†µí•´ ì¬ìƒì„±í•˜ë©´ ì„œë¡œ ë‹¤ë¥¸ ê²°ê³¼ ê°’ì„ ë§Œë“¤ê²Œ ëœë‹¤. ìœ„ì™€ ê°™ì€ ì›ë¦¬ë¥¼ í™œìš©í•˜ì—¬ VAEë¥¼ ê°ì§€í•  ìˆ˜ ìˆë‹¤.

##### VAEë¥¼ ì´ìš©í•œ ì´ìƒê°ì§€ python ì½”ë“œ:

1. pyodì—ì„œ ì œê³µí•˜ëŠ” ëª¨ë“ˆ í™œìš©:

```python
from pyod.models.thresholds import VAE

```

2. pythonì„ í™œìš©í•œ VAE(MIST ë°ì´í„° ì…‹):

```python
import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import tensorflow_datasets as tfds
from tensorflow.keras import Model, layers
from matplotlib import pyplot as plt
```

```python
dataset = tfds.load('mnist', split = 'train')
```

ë°ì´í„°ë¥¼ ë¡œë“œ í•œë‹¤.

```python
batch_size = 1024
train_data = dataset.map(lambda data: tf.cast(data['image'], tf.float32)/255.).batch(batch_size)
```

ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬ í•´ì¤€ë‹¤. ì—¬ê¸°ì„œ tf.cast í•¨ìˆ˜ëŠ” í…ì„œì˜ ìë£Œí˜•ì„ ë°”ê¾¸ëŠ” í•¨ìˆ˜ì´ë‹¤.

**<Encoder>**

```python
class Vanila_Encoder(Model):
    def __init__(self, latent_dim):
        super().__init__()
        self.latent_dim = latent_dim
        self.encoder = tf.keras.Sequential([
            layers.Flatten(),
            layers.Dense(512, activation = "relu")
            layers.Dense(256, activation = "relu"),
            layers.Dense(latent_dim * 2)
        ])

    def __call__(self, x):
        #self.encoder(x)ê°€ ë„ì¶œí•œ ê°ê°ì˜ ê°’ì„ mu, logvarë¡œ mapping
        #tf.split: value into a list of subentsors
        mu, logvar = tf.split(self.encoder(x), 2, axis = 1)
        return mu, logvar
```

**<Decoder>**

```python
class Vanila_Decoder(Model):
    def __init__(self, latent_dim):
        super().__init__()

        self.latent_dim = latent_dim
        self.decoder = tf.keras.Sequential([
            layers.Dense(256, activation = "relu"),
            layers.Dense(512, activation = "relu"),
            layers.Dense(784, activation = "sigmoid"),
            layers.Reshape((28, 28, 1))
        ])

    def __call__(self, z):
        return self.decoder(z)
```

##### Sampling ë° train_step êµ¬í˜„

```python

def sample(mu, logvar):
    epsilon = tf.random.normal(mu.shape)
    sigma = tf.exp(0.5* logvar)
    return epsilon*sigma + mu
```

**<Train VAE>**

```python

def train_step(inputs):
    #Graient Tapeì—ì„œ gradient ê°’ë“¤ì„ ìˆ˜ì§‘í•¨
    with tf.GradientTape() as tape:
        # Encoderë¡œë¶€í„° mu, logvarë¥¼ ì–»ìŒ: q(z/x)
        mu, logvar = encoder(inputs)
        #mu, logvarë¥¼ ì‚¬ìš©í•´ì„œ reparameterization trick ìƒì„±
        z = sample(mu, logvar)
        # rparameterization tickì„ Decoderì— ë„£ì–´ reconstruct xë¥¼ ì–»ëŠ”ë‹¤.
        x_recon = decoder(z)
        #ì…ë ¥ê³¼ ìƒì„±ëœ ì´ë¯¸ì§€ì˜ ì°¨ì´
        reconstruction_error = tf.reduce_sum(tf.losses.binary_crossentopy(inputs, x_recon))
        #KLì„ êµ¬í•œë‹¤
        kl = 0.5*tf.reduce_sum(tf.exp(logvar) + tf.square(mu) - 1. - logvar)
        # inputs.shape[0] # of sapmples
        loss = (kl + reconstruction_error) / inputs.shape[0]
        #get trainable parameter
        vars_ = encoder.trainable_variables + decoder.trainable_variables
        # get grads
        grads_ = tape.gradient(loss, vars_)
        # apply gradient descent
        optimizer.apply_gradients(zip(grads_, vars_))
    return loss, reconstruction_error, kl
```

##### ëª¨ë¸ êµ¬ì„± ë° í•™ìŠµ

```python
# Set hyperparameters

n_epochs = 50
latent_dim = 2
learning_rate = 1e-3
log_interval = 10

encoder = Vanila_Encoder(latent_dim)
decoder = Vanila_Decoder(latent_dim)
optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)
```

```python

for epoch in range(1, n_epochs + 1):
    total_loss, total_recon, total_kl = 0, 0, 0
    for x in train_data:
        loss, recon, kl = train_step(x)
        #loss ì €ì¥
        total_loss += loss *x.shape[0]
        #error ì €ì¥
        total_recon += recon
        #total KL ì €ì¥
        total_kl += kl

    if epoch % log_interval == 0:
        print(
            f'{epoch:3d} iteration: ELBO {total_loss / len(dataset):.2f}, ' \
            f'Recon {total_recon / len(dataset):.2f}, ' \
            f'KL {total_kl / len(dataset):.2f}'
        )
```

#### AnoGanì„ í™œìš©í•œ ì´ìƒê°ì§€

##### AnoGan ê°œë…:

í•´ë‹¹ í¬ìŠ¤íŠ¸ëŠ” [AnoGAN\_í¬ìŠ¤íŠ¸](https://ffighting.net/deep-learning-paper-review/anomaly-detection/anogan/)ë¥¼ ì°¸ê³ í•˜ì˜€ë‹¤.

AnoGanì€ ì´ìƒ ê°ì§€ë¥¼ ìœ„í•´ Ganì„ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ìœ¼ë¡œ GANê³¼ ìœ ì‚¬í•˜ë‚˜ í•™ìŠµí•  ë•Œ ì •ìƒ ì´ë¯¸ì§€ë§Œ í•™ìŠµí•œë‹¤ëŠ” ì ì—ì„œ GANê³¼ ë‹¤ë¥´ë‹¤.

**[AnoGan ëª¨ë¸ Summary]**

![AnoGan]({{site.url}}/images/2023-07-19-BearingProject/anogan.png){: .align-center}

AnoGanì—ì„œëŠ” í•™ìŠµ ë‹¨ê³„ì—ì„œ ì •ìƒ ì´ë¯¸ì§€ë§Œ í•™ìŠµì„ í•œë‹¤. ì´ë ‡ê²Œ í•™ìŠµì‹œ, GeneratorëŠ” ì •ìƒ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œë§Œ í•™ìŠµì„ í–ˆê¸° ë•Œë¬¸ì— ìƒì„±í•  ìˆ˜ ìˆëŠ” distribution ë˜í•œ ì •ìƒ ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ distributionì´ë‹¤. ì´ëŸ°ì‹ìœ¼ë¡œ Generatorê°€ ì •ìƒ distributionë§Œ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í•™ìŠµì„ ì‹œí‚¨ ìƒí™©ì—ì„œ ì´ìƒ ì´ë¯¸ì§€ê°€ Generatorê°€ ë“¤ì–´ê°€ê²Œ ë˜ë©´, ìƒì„±ëœ ì´ë¯¸ì§€ì™€ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì‚¬ì´ì˜ ì°¨ì´ê°€ í¬ê²Œ ë  ê²ƒì´ë‹¤.ì´ëŸ° ì›ë¦¬ë¥¼ í™œìš©í•˜ì—¬ ì´ìƒì¹˜ë¥¼ ê°ì§€í•˜ê²Œ ëœë‹¤.

![AnoGan1]({{site.url}}/images/2023-07-19-BearingProject/anogan_1.png){: .align-center}

**[AnoGan train ë‹¨ê³„]**

![AnoGan_train]({{site.url}}/images/2023-07-19-BearingProject/anogan_train.png){: .align-center}

AnoGanì€ ì •ìƒ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê²Œ ëœë‹¤. GeneratorëŠ” latent vector zë¡œë¶€í„° ì´ë¯¸ì§€ G(z)ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ëª¨ë“ˆì´ë‹¤. í•™ìŠµ ë‹¨ê³„ì—ì„œëŠ” ìƒì„±ëœ G(z)ë¥¼ Discriminatorê°€ ì •ìƒ ì´ë¯¸ì§€ì¸ì§€, Generatorê°€ ë§Œë“¤ì–´ë‚¸ ì´ë¯¸ì§€ì¸ì§€ êµ¬ë¶„í•˜ë„ë¡ í•™ìŠµì„ í•˜ê²Œ ëœë‹¤.

![AnoGan_train]({{site.url}}/images/2023-07-19-BearingProject/anogan_train1.png){: .align-center}

**[Inference ë‹¨ê³„]**

![AnoGan_inference]({{site.url}}/images/2023-07-19-BearingProject/anogan_inference.png){: .align-center}

AnoGanì—ì„œëŠ” ë‹¨ìˆœíˆ ì •ìƒ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•´ì„œëŠ” ë¶ˆëŸ‰ ìœ ë¬´ë¥¼ íŒë‹¨í•  ìˆ˜ ì—†ë‹¤. Generatorê°€ ì…ë ¥ìœ¼ë¡œ ë°›ì€ ì´ë¯¸ì§€ì™€ ê°€ì¥ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ê°–ë„ë¡ ì¶”ë¡  ë‹¨ê³„ë¥¼ ê±°ì³ì•¼ í•œë‹¤.

ì´ë¥¼ ìœ„í•´ì„œëŠ” Generatorê°€ ìƒì„±í•œ ì´ë¯¸ì§€ì¸ G(z)ê°€ xì™€ ìœ ì‚¬í•´ì§€ë„ë¡ í•˜ëŠ” zë¥¼ ì°¾ì•„ì•¼ í•œë‹¤. G(z)ì™€ xì˜ ì°¨ì´ê°€ ìµœì†Œê°€ ë˜ë„ë¡ loss functionì„ ì„¤ê³„í•œ í›„ ëª¨ë¸ì„ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•´ì•¼ í•œë‹¤.

**ì´ë•Œ ì‚¬ìš©ë˜ëŠ” loss functionì€ ë‘ ê°€ì§€ì´ë‹¤.**

**ì²«ë²ˆì§¸ëŠ” ì…ë ¥ ì´ë¯¸ì§€(x)ì™€ ìƒì„±ëœ ì´ë¯¸ì§€ê°€ image levelì—ì„œ ê°™ì•„ì§€ë„ë¡ í•˜ëŠ” loss functionì´ë‹¤.**

![AnoGan_l1]({{site.url}}/images/2023-07-19-BearingProject/anogan_l1.png){: .align-center}

**ë‘ë²ˆì§¸ lossëŠ” ìƒì„±í•œ ì´ë¯¸ì§€ì™€ ì…ë ¥ë°›ì€ ì´ë¯¸ì§€ê°€ Discriminatorì˜ feature levelì—ì„œ ê°™ì•„ì§€ë„ë¡ ìœ ë„í•´ì£¼ëŠ” lossì´ë‹¤.**

![AnoGan_l2]({{site.url}}/images/2023-07-19-BearingProject/anogan_l2.png){: .align-center}

**ìµœì¢… lossëŠ” ë‘ê°€ì§€ lossë¡œ êµ¬ì„±í•´ì¤€ë‹¤.**

![AnoGan_l3]({{site.url}}/images/2023-07-19-BearingProject/anogan_l3.png){: .align-center}

í•´ë‹¹ ìµœì¢… lossëŠ” anomaly scoreë¡œë„ ì‚¬ìš©ëœë‹¤.

#### AnoGan ì½”ë“œ:

##### **[DCGAN + AE (CIFAR10 ë°ì´í„°)]**

##### **1.ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬, í•¨ìˆ˜ Import**

```python
!pip install tensorboardX
```

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch import autograd, optim
from torch.utils.data import DataLoader, Dataset

import torchvision
from torchvision.datasets import CIFAR10
from torchvision import transforms
from torchvision.utils import save_image
from tensorboardX import SummaryWriter

import numpy as np
import matplotlib.pyplot as plt
import random
import cv2
import skimage
import skimage.io

torch.manual_seed(0)
np.random.seed(0)
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.determinstic = False

writer = SummaryWriter(logdir='runs/DCGAN_training_5')
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(torch.__version__)
```

##### **2.GAN í›ˆë ¨ ë¶€ë¶„**

##### **1.Model Architecture**

##### **1-1.Generator(latent zë¥¼ í†µí•´ ì´ë¯¸ì§€ ìƒì„±)**

```python
class Generator(nn.Module):
    def __init__(self, latent_dim=100, ngf = 28, channels=1, bias = True):
        super().__init__()

        self.model = nn.Sequential(
            nn.ConvTranspose2d(latent_dim, ngf*8, kernel_size=4, stride=1, padding=0, bias=bias),
            nn.BatchNorm2d(ngf*8),
            nn.ReLU(),

            nn.ConvTranspose2d(ngf*8, ngf*4, kernel_size=4, stride=2, padding=1, bias=bias),
            nn.BatchNorm2d(ngf*4),
            nn.ReLU(),

            nn.ConvTranspose2d(ngf*4, ngf*2, kernel_size=4, stride=2, padding=1, bias=bias),
            nn.BatchNorm2d(ngf*2),
            nn.ReLU(),

            nn.ConvTranspose2d(ngf*2, ngf, kernel_size=4, stride=2, padding=1, bias=bias),
            nn.BatchNorm2d(ngf),
            nn.ReLU(),

            nn.ConvTranspose2d(ngf, channels, kernel_size=4, stride=2, padding=1, bias=bias),
            nn.Tanh()
        )

    def forward(self, z):
        return self.model(z)
```

##### **1-2.Discriminator(ì´ë¯¸ì§€ê°€ Realì¸ì§€ Fakeì¸ì§€ êµ¬ë³„)**

```python
class Discriminator(nn.Module):
    def __init__(self, ndf=28, channels=1, bias=True):
        super().__init__()

        def discriminator_block(in_features, out_features, bn=True):
            if bn:
                block = [
                         nn.Conv2d(in_features, out_features, 4, 2, 1, bias=bias),
                         nn.BatchNorm2d(out_features),
                         nn.LeakyReLU(0.2, inplace=True) # Generatorì— ë¯¸ë¶„ê°’ì„ ë” ì˜ ì „ë‹¬í—¤ì£¼ê¸° ìœ„í•´ LeakyReLU ì‚¬ìš©.
                ]
            else:
                block = [
                         nn.Conv2d(in_features, out_features, 4, 2, 1, bias=bias),
                         nn.LeakyReLU(0.2, inplace=True)
                ]
            return block

        self.features = nn.Sequential(
            *discriminator_block(channels, ndf, bn=False),
            *discriminator_block(ndf, ndf*2, bn=True),
            *discriminator_block(ndf*2, ndf*4, bn=True),
            *discriminator_block(ndf*4, ndf*8, bn=True)
        )

        self.last_layer = nn.Sequential(
            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=bias),
            nn.Sigmoid()
        )

    def forward_features(self, x):
        features = self.features(x)
        return features

    def forward(self, x):
        features = self.forward_features(x)
        validity = self.last_layer(features)
        return validity
```

##### **1-3.Encoder(latent z ìƒì„±)**

```python
class Encoder(nn.Module):
    def __init__(self, latent_dim=100, ndf=28, channels=1, bias=True):
        super().__init__()

        def encoder_block(in_features, out_features, bn=True):
            if bn:
                block = [
                         nn.Conv2d(in_features, out_features, 4, 2, 1, bias=bias),
                         nn.BatchNorm2d(out_features),
                         nn.LeakyReLU(0.2, inplace=True)
                ]
            else:
                block = [
                         nn.Conv2d(in_features, out_features, 4, 2, 1, bias=bias),
                         nn.LeakyReLU(0.2, inplace=True)
                ]
            return block

        self.features = nn.Sequential(
            *encoder_block(channels, ndf, bn=False),
            *encoder_block(ndf, ndf*2, bn=True),
            *encoder_block(ndf*2, ndf*4, bn=True),
            *encoder_block(ndf*4, ndf*8, bn=True),
            nn.Conv2d(ndf*8, latent_dim, 4, 1, 0, bias=bias),
            nn.Tanh()
        )

    def forward(self, x):
        validity = self.features(x)
        return validity
```

##### **2. Hyper Parameters**

```python
n_epochs = 200
batch_size = 128
lr = 0.0002
ndf = 64
ngf = 64
latent_dim = 100
img_size = 64
channels = 3
n_critic = 5
split_rate = 0.8
```

##### **Data**

```python

class SimpleDataset(Dataset):
    def __init__(self, data, labels, transform=None):
        self.transform = transform
        self.data = data
        self.labels = labels

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        data = np.transpose(self.data[idx], (2, 0, 1))
        labels = self.labels[idx]

        if self.transform:
            data = self.transform(data)


        return data, labels
```

##### **Train Data, Data Loader ì •ì˜**

```python
# Train Data
train_dataset = CIFAR10('./', train=True, download=True)

_x_train = torch.ByteTensor(train_dataset.data[torch.IntTensor(train_dataset.targets) == 1])
x_train, x_test_normal = _x_train.split((int(len(_x_train) * split_rate)), dim=0)

train_dataset_target = torch.Tensor(train_dataset.targets)
_y_train = train_dataset_target[train_dataset_target == 1]
y_train, y_test_normal = _y_train.split((int(len(_y_train) * split_rate)), dim=0)

train_mnist = SimpleDataset(x_train, y_train,
                                transform=transforms.Compose(
                                    [transforms.ToPILImage(),
                                     transforms.Resize(img_size),
                                     transforms.ToTensor()])
                                )
train_dataloader = DataLoader(train_mnist, batch_size=batch_size, shuffle=True)

```

##### **DCGAN í•™ìŠµ**

##### **4-1.optimizer í•¨ìˆ˜, GAN ëª¨ë¸ ì •ì˜**

##### **layer weight ì´ˆê¸°í™”**

```python
# custom weights initialization called on netG and netD
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        torch.nn.init.normal_(m.weight, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        torch.nn.init.normal_(m.weight, 1.0, 0.02)
        torch.nn.init.zeros_(m.bias)

```

```python
G = Generator(latent_dim = latent_dim, ngf=ngf, channels=channels, bias=False).to(device)
G.apply(weights_init)
D = Discriminator(ndf=ndf, channels=channels, bias=False).to(device)
D.apply(weights_init)

optimizer_G = optim.Adam(G.parameters(), lr=lr, weight_decay=1e-5, betas=(0.5, 0.999))
optimizer_D = optim.Adam(D.parameters(), lr=lr, weight_decay=1e-5, betas=(0.5, 0.999))
```

## âš™ NASA Bearing Dataset í”„ë¡œì íŠ¸

### NASA Bearing Dataset ì„¤ëª…:

ìƒ¤í”„íŠ¸(íšŒì „í•˜ëŠ” ê¸°ê³„ìš”ì†Œë¡œ, ë³´í†µ ë‹¨ë©´ì´ ì›í˜•ì´ë©°, í•œ ë¶€ë¶„ì—ì„œ ë‹¤ë¥¸ ë¶€ë¶„ìœ¼ë¡œ, ë˜ëŠ” ì „ë ¥ì„ ìƒì‚°í•˜ëŠ” ê¸°ê³„ì—ì„œ ì „ë ¥ì„ í¡ìˆ˜í•˜ëŠ” ê¸°ê³„ë¡œ ì „ë‹¬í•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤.)ì— ì´ 4ê°œì˜ ë² ì–´ë§ì´ ìˆë‹¤. íšŒì „ ì†ë„ëŠ” 2000 RPMì´ë©° ìŠ¤í”„ë§ì˜ ì›ë¦¬ë¡œ ì¸í•´ ì¶• ì¤‘ì‹¬ì˜ ìˆ˜ì§ìœ¼ë¡œ ì‘ìš©í•˜ëŠ” í•˜ì¤‘ì´ 6000ibsì´ë‹¤. ëª¨ë“  ë² ì–´ë§ì—ëŠ” ìœ¤í™œì¬ê°€ ë°œë¼ì ¸ ìˆë‹¤.

NASA Bearing Datasetì—ëŠ” í¬ê²Œ 3ê°€ì§€ ë°ì´í„°ë“¤ì´ ë“¤ì–´ ìˆë‹¤. ê°ê°ì˜ ë°ì´í„°ë“¤ì€ ì •ìƒì—ì„œ ê³ ì¥ë‚  ë•Œê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ë‹´ê³  ìˆë‹¤. ê° ë°ì´í„°ë“¤ì€ 1ì´ˆì— í•œë²ˆ ì¸¡ì •í•œ ì§„ë™ ë°ì´í„° ì…‹ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆê³  ê°ê°ì˜ íŒŒì¼ì´ 20,480 í¬ì¸ì¸ ì™€ 20kHzì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¡œ ì¶”ì¶œë˜ì—ˆë‹¤.

ğŸ›¢ ë°ì´í„°ì…‹ 1:

â˜‘ ë°ì´í„°ì…‹ 1ì€ 1ê°œì˜ ë² ì–´ë§ ë‹¹ 2ê°œì˜ ì—‘ì…€ë¡œë¯¸í„°(x,y ì¶•)ì„ ë‚˜íƒ€ë‚¸ ë°ì´í„° ì…‹ì´ë‹¤.

â˜‘ ì‹œê¸°:
03.10.22~03.11.25

â˜‘ 2156ê°œì˜ íŒŒì¼

â˜‘ 8ê°œì˜ ì±„ë„(4ê°œì˜ ë² ì–´ë§, ê° ë² ì–´ë§ ë‹¹ 2ê°œì˜ ê°€ì†ë„ê³„)

ë² ì–´ë§ 1: 1, 2 ì±„ë„
ë² ì–´ë§ 2: 3, 4 ì±„ë„
ë² ì–´ë§ 3: 5, 6 ì±„ë„
ë² ì–´ë§ 4: 7, 8 ì±„ë„

âœ… ë§ˆì§€ë§‰ì—ëŠ” ë² ì–´ë§ 3, ë² ì–´ë§ 4ê°€ ì™„ì „íˆ ê³ ì¥ë‚˜ëŠ” êµ¬ì¡°

ë°ì´í„°ì…‹ 2, 3ì€ 1ê°œì˜ ë² ì–´ë§ ë‹¹ 1ê°œì˜ ì—‘ì…€ë¡œë¯¸í„°ë¥¼ ë‚˜íƒ€ë‚¸ ë°ì´í„° ì…‹ì´ë‹¤.

ğŸ›¢ ë°ì´í„° ì…‹ 2:

â˜‘ ì‹œê¸°:
04.02.12~04.02.19

â˜‘ 984ê°œ íŒŒì¼

â˜‘ 4ê°œ ì±„ë„(4ê°œì˜ ë² ì–´ë§, ê° 1ê°œì˜ ê°€ì†ë„ê³„)

ë² ì–´ë§1: ì±„ë„ 1
ë² ì–´ë§2: ì±„ë„ 2
ë² ì–´ë§3: ì±„ë„ 3
ë² ì–´ë§4: ì±„ë„ 4

âœ… ê²°êµ­ ë² ì–´ë§ 1ì—ì„œ ì™„ì „íˆ ê³ ì¥ë‚˜ëŠ” ë°ì´í„° ì…‹

### ğŸ“Š ë°ì´í„°ì…‹ 2 ë¶„ì„

Nasa ë°ì´í„° ì…‹ì—ì„œ ìš°ì„  ê° ë² ì–´ë§ ë³„ë¡œ ì±„ë„ì´ 1ê°œì¸ ë°ì´í„° ì…‹ 2ë²ˆì„ ë¶„ì„í•˜ì˜€ë‹¤. Nasa Bearing Dataset íŠ¹ì„± ìƒ ì •ìƒì´ì—ˆë˜ ë² ì–´ë§ì´ ì‹œê°„ì´ ê°ˆìˆ˜ë¡ ë§ˆëª¨ê°€ ë˜ì–´ ê²°í•¨ì´ ë°œìƒí•´ ë¹„ì •ìƒ ë°ì´í„°ë¡œ ë°”ë€ŒëŠ” ê³¼ì •ì„ ë‹´ì•˜ìœ¼ë¯€ë¡œ ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„ì´ ê²°í•¨ ë°œìƒ ì‹œì ì„ ê²°ì •í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤ê³  íŒë‹¨í•˜ì˜€ë‹¤.ë°ì´í„° íŠ¹ì„±ìƒ ê²°í•¨ ê³¼ ë¹„ê²°í•¨ ë¶€ë¶„ì„ labeling í•˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ í†µê³„ì ì¸ ë°©ë²• ë° ë¹„ì§€ë„ í•™ìŠµ ë°©ì‹ì„ í™œìš©í•˜ì—¬ ì ‘ê·¼í•˜ì˜€ë‹¤.
