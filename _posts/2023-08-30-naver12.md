layout: single
title: "[네이버부스트AI준비]/확률론"
categories: 네이버부스트AI
tag: [Python]
toc: true
author_profile: false
sidebar:
nav: "docs"

---

# 확률론:

- 딥러닝은 **확률론 기반의 기계학습 이론**에 바탕을 두고 있다.
- 회귀 분석에서 손실함수로 사용되는 L2노름은 **예측오차의 분산을 가장 최소화하는 방향으로 학습**하도록 유도한다.
- 분류 문제에서 사용되는 교차엔트로피는 **모델 예측의 불확실성을 최소화하는 방향으로 학습**하도록 유도한다.

## 확률 분포:

- 데이터 공간을 x\*y라 표기하고 D는 데이터 공간에서 데이터를 추출하는 분포이다.

![확률분포]({{site.url}}/images/2023-08-30-naver12/확률분포.png){: .align-center}

**[이산 확률변수 vs 연속확률변수]**

- 확률변수는 확률분포 D에 따라 **이산형**과 **연속형** 확률변수로 구분된다.

[이산 확률변수]

이산형 확률변수는 **확률변수가 가질 수 있는 경우의 수**를 모두 고려하여 **확률을 더해서 모델링**한다

![이산형]({{site.url}}/images/2023-08-30-naver12/이산형.png){: .align-center}

[연속확률변수]

연속 확률변수는 **데이터 공간에 정의된 확률변수의 밀도** 위에서의 **적분을 통해 모델링**한다.

이때 사용되는 P(X)는 밀도로 누적 확률 분포의 변화율을 모델링한 것이며 확률로 해석하면 안된다.

![연속형]({{site.url}}/images/2023-08-30-naver12/연속형.png){: .align-center}

결합 분포 P(x, y)가 D를 모델링한다고 했을 때 P(X)는 입력 x에 대한 주변확률분포로 y에 대한 정보를 주진 않는다.

![p(x)1](<{{site.url}}/images/2023-08-30-naver12/p(x)1.png>){: .align-center}

위 식을 도식화 하면, 아래와 같이 표현할 수 있다.

![p(x)](<{{site.url}}/images/2023-08-30-naver12/p(x).png>){: .align-center}

## 조건부확률과 기계학습

- 조건부확률 P(y|x)는 입력 변수 x에 대해 정답이 y일 확률을 의미한다.
- 로지스틱 회귀에서 사용했던 선형모델과 소프트맥스 함수의 결합은 **데이터에서 추출된 패턴을 기반으로 확률을 해석**하는 데 사용된다

### 기댓값이란?

확률 분포가 주어지면 데이터를 분석하는 데 사용 가능한 여러 종류의 **통계적 범함수를 계산**할 수 있다.

**기대값은 데이터를 대표하는 통계량**이면서 동시에 확률 분포를 통해 다른 통계적 범함수를 계산하는 데 사용된다. 사실 기대값은 평균과도 같은 말이다. 하지만 기계학습에서는 기대 값이 평균을 구하는 것에 그치지 않고 목적으로 하는 주어진 함수가 있을 때 그 함수의 기대 값을 구하는 것을 통해서 데이터를 해석하려고 했을 때 여러가지 방면으로 생각해 볼 수 있다.

![기대값]({{site.url}}/images/2023-08-30-naver12/기대값.png){: .align-center}

연속확률분포 같은 경우, 주어진 함수에 확률밀도 함수를 곱하여 적분을 통해 기대값을 구한다.
이산확률분포 같은 경우, 주어진 함수에 확률질량 함수를 곱하여 summation을 통해 기대 값을 구한다.

기대 값을 이용하면 다양한 통계량을 구할 수 있다.

![기대값1({{site.url}}/images/2023-08-30-naver12/기대값1.png){: .align-center}

### 몬테카를로 샘플링

- 기계학습의 많은 문제들은 확률분포를 명시적으로 모를 떄가 대부분이다.
- 확률분포를 모를 때 **데이터를 이용하여 기대값을 계산하려면 몬테카를로 샘플링 방법을 사용**해야 한다.

![몬테카를로]({{site.url}}/images/2023-08-30-naver12/몬테카를로.png){: .align-center}

- 몬테카를로 샘플링은 독립추출만 보장된다면 대수의 법칙(Law of Large Number)에 의해서 수렴성을 보장한다.

확률변수가 상호독립적일 때, 모두 동일한 확률분포를 가진다면 기대값을 랜덤하게 뽑은 n개 샘플의 평균치와 유사하다

[몬테 카를로 예제: 적분 계산]

![몬테카를로1]({{site.url}}/images/2023-08-30-naver12/몬테카를로1.png){: .align-center}

위 함수 f(x)의 적분 값을 구하려고 할 때, 고등학교에서 배웠던 부분적분을 활용하여 적분 값을 구하는 것은 쉽지 않다. 대신 이를 몬테카를로 샘플링으로 구하면 쉽게 구할 수 있다.

![몬테카를로2]({{site.url}}/images/2023-08-30-naver12/몬테카를로2.png){: .align-center}

## 모수란?

- **통계적 모델링은 적절한 가정 위에서 확률분포를 추정(inference)**하는 것이 목표이다.
- 그러나 유한한 개수의 데이터만 관찰해서 모집단의 분포를 정확하게 안다는 것은 불가능하므로, **근사적으로 확률분포를 추정**할 수 밖에 없다.
- 데이터가 특정 확률분포를 따른다고 선험적으로 가정한 후 그 분포를 결정하는 모수(parameter)를 추정하는 방법을 **모수적 방법론**이라고 한다.
- 특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 바뀌면 **비모수 방법론**이라고 부른다.

### 확률분포 가정하기:

- 확률분포를 가정하는 방법: 히스토그램을 통해 모양을 관찰한다.

  - 데이터가 2개의 값(0 또는 1)만 가지는 경우: 베르누이분포
  - 데이터가 n개의 이산적인 값을 가지는 경우: 카테고리분포
  - 데이터가 [0,1] 사이에서 값을 가지는 경우: 베타분포
  - 데이터가 0 이상의 값을 가지는 경우: 감마분포, 로그분포
  - 데이터가 R 전체에서 값을 가지는 경우: 정규분포, 라플라스 분포

**[정규 분포의 모수]**

![정규분포]({{site.url}}/images/2023-08-30-naver12/정규분포.png){: .align-center}

**[중심극한정리]**

**통계량의 확률분포를 표집분포**라 부르며, 특히 표본편균의 표집분포는 N이 커질 수록 정규분포를 따른다.

## 최대가능도 추정법

- 표본 평균이나 표본 분산은 중요한 통계량이지만 확률분포마다 사용하는 모수가 다르므로 적절한 통계량이 달라지게 된다.
- 이론적으로 가장 가능성이 높은 모수를 추정하는 방법 중 하나는 **최대가능도 추정법**이다.

![최대가능도]({{site.url}}/images/2023-08-30-naver12/최대가능도.png){: .align-center}
